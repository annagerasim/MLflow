{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e996d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844a3557",
   "metadata": {},
   "source": [
    "This workbook contains the flow I used for pulling and parsing through different files. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e7b8f4",
   "metadata": {},
   "source": [
    "The script below pulls the Lung Transplant Studies from the Red Cap database and saves it to the folder in this directory. Comment it out once done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0184aae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 14887 records\n",
      "\n",
      "['LT001', 'LT002', 'LT003', 'LT004', 'LT005', 'LT006', 'LT007', 'LT008', 'LT009', 'LT010', 'LT011', 'LT012', 'LT013', 'LT014', 'LT015', 'LT016', 'LT017', 'LT018', 'LT019', 'LT020', 'LT021', 'LT022', 'LT023', 'LT024', 'LT025', 'LT026', 'LT027', 'LT028', 'LT029', 'LT030', 'LT031', 'LT032', 'LT033', 'LT034', 'LT035', 'LT036', 'LT037', 'LT038', 'LT039', 'LT040', 'LT041', 'LT042', 'LT043', 'LT044', 'LT045', 'LT046', 'LT047', 'LT048', 'LT049', 'LT050', 'LT051', 'LT052', 'LT053', 'LT054', 'LT055', 'LT056', 'LT057', 'LT058', 'LT059', 'LT060', 'LT061', 'LT062', 'LT063', 'LT064', 'LT065', 'LT066', 'LT067', 'LT068', 'LT069', 'LT070', 'LT071', 'LT072', 'LT073', 'LT074', 'LT075', 'LT076', 'LT077', 'LT078', 'LT079', 'LT080', 'LT081', 'LT082', 'LT083', 'LT084', 'LT085', 'LT086', 'LT087', 'LT088', 'LT089', 'LT090', 'LT091', 'LT092', 'LT093', 'LT094', 'LT095', 'LT096', 'LT097', 'LT098', 'LT099', 'LT100', 'LT101', 'LT102', 'LT103', 'LT104', 'LT105', 'LT106', 'LT107', 'LT108', 'LT109', 'LT110', 'LT111', 'LT112', 'LT113', 'LT114', 'LT115', 'LT116', 'LT117', 'LT118', 'LT119', 'LT121', 'LT122', 'LT123', 'LT124', 'LT125', 'LT126', 'LT127', 'LT128', 'LT129', 'LT130', 'LT131', 'LT132', 'LT133', 'LT134', 'LT135', 'LT136', 'LT137', 'LT138', 'LT139', 'LT140', 'LT141', 'LT142', 'LT143', 'LT144', 'LT146', 'LT147', 'LT148', 'LT149', 'LT150', 'LT151', 'LT152', 'LT153', 'LT154', 'LT155', 'LT156', 'LT157', 'LT158', 'LT159', 'LT160', 'LT161', 'LT162', 'LT163', 'LT164', 'LT165', 'LT166', 'LT167', 'LT168', 'LT169', 'LT170', 'LT171', 'LT172', 'LT173', 'LT174', 'LT175', 'LT176', 'LT177', 'LT178', 'LT179', 'LT180', 'LT181', 'LT182', 'LT183', 'LT184', 'LT185', 'LT186', 'LT187', 'LT188', 'LT189', 'LT190', 'LT191', 'LT192', 'LT193', 'LT194', 'LT195', 'LT196', 'LT197', 'LT198', 'LT199', 'LT200', 'LT201', 'LT202', 'LT203', 'LT204', 'LT205', 'LT206', 'LT207', 'LT208', 'LT209', 'LT210', 'LT211', 'LT212', 'LT213', 'LT214', 'LT215', 'LT216', 'LT217', 'LT218', 'LT219', 'LT220', 'LT221', 'LT222', 'LT223', 'LT224', 'LT225', 'LT226', 'LT227', 'LT228', 'LT229', 'LT230', 'LT231', 'LT232', 'LT233', 'LT234', 'LT235', 'LT236', 'LT237', 'LT238', 'LT239', 'LT240', 'LT241', 'LT242', 'LT243', 'LT244', 'LT245', 'LT246', 'LT247', 'LT248', 'LT249', 'LT250', 'LT251', 'LT252', 'LT253', 'LT254', 'LT255', 'LT256', 'LT257', 'LT258', 'LT259', 'LT260', 'LT261', 'LT262', 'LT263', 'LT264', 'LT265', 'LT266', 'LT267', 'LT268', 'LT269', 'LT270', 'LT271', 'LT272', 'LT273', 'LT274', 'LT275', 'LT276', 'LT277', 'LT278', 'LT279', 'LT280', 'LT281', 'LT282', 'LT283', 'LT284', 'LT285', 'LT286', 'LT287', 'LT288', 'LT289', 'LT290', 'LT291', 'LT292', 'LT293', 'LT294', 'LT295', 'LT296', 'LT297', 'LT298', 'LT299', 'LT300', 'LT301', 'LT302', 'LT303', 'LT304', 'LT305', 'LT306', 'LT307', 'LT308', 'LT309', 'LT310', 'LT311', 'LT312', 'LT313', 'LT314', 'LT315', 'LT316', 'LT317', 'LT318', 'LT319', 'LT320', 'LT321', 'LT322', 'LT323', 'LT324', 'LT325', 'LT326', 'LT327', 'LT328', 'LT329', 'LT330', 'LT331', 'LT332', 'LT333', 'LT334', 'LT335', 'LT336', 'LT337', 'LT338', 'LT339', 'LT340', 'LT341', 'LT342', 'LT343', 'LT344', 'LT345', 'LT346', 'LT347', 'LT348', 'LT349', 'LT350', 'LT351', 'LT352', 'LT353', 'LT354', 'LT355', 'LT356', 'LT357', 'LT358', 'LT359', 'LT360', 'LT361']\n",
      "File‑upload fields: ['samples_photo', 'lung_bx_photo_1', 'lung_bx_photo_2', 'lung_bx_photo_3', 'lung_bx_photo_4', 'lung_bx_photo_5', 'lung_bx_photo_6', 'lung_bx_photo_7', 'lung_bx_photo_8', 'lung_bx_photo_9', 'lung_bx_photo_10', 'lung_bx_photo_11', 'lung_bx_photo_12', 'bal1_sort_report', 'bal1_sort_fcs', 'bal2_sort_report', 'bal2_sort_fcs', 'bal3_sort_report', 'bal3_sort_fcs', 'bal4_sort_report', 'bal4_sort_fcs']\n",
      "Wrote all_LT_new_trial/20210923_LT001_LUL_23092021171938.pdf\n",
      "Wrote all_LT_new_trial/20210923_LT001_LUL_001.fcs\n",
      "Wrote all_LT_new_trial/20210923_LT001_RML_23092021172713.pdf\n",
      "Wrote all_LT_new_trial/20210923_LT001_RML_001.fcs\n",
      "No file for LT001‑bal3_sort_report (HTTP 400)\n",
      "No file for LT001‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT001‑bal4_sort_report (HTTP 400)\n",
      "No file for LT001‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20210930_LT002_LUL_30092021174916.pdf\n",
      "Wrote all_LT_new_trial/20210930_LT002_LUL_001.fcs\n",
      "Wrote all_LT_new_trial/20210930_LT002_RML_30092021174212.pdf\n",
      "Wrote all_LT_new_trial/20210930_LT002_RML_001.fcs\n",
      "No file for LT002‑bal3_sort_report (HTTP 400)\n",
      "No file for LT002‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT002‑bal4_sort_report (HTTP 400)\n",
      "No file for LT002‑bal4_sort_fcs (HTTP 400)\n",
      "No file for LT003‑bal1_sort_report (HTTP 400)\n",
      "No file for LT003‑bal1_sort_fcs (HTTP 400)\n",
      "No file for LT003‑bal2_sort_report (HTTP 400)\n",
      "No file for LT003‑bal2_sort_fcs (HTTP 400)\n",
      "No file for LT003‑bal3_sort_report (HTTP 400)\n",
      "No file for LT003‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT003‑bal4_sort_report (HTTP 400)\n",
      "No file for LT003‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20231116_LT004 LUL_16112023171929.pdf\n",
      "Wrote all_LT_new_trial/20231116_LT004 LUL_001.fcs\n",
      "Wrote all_LT_new_trial/20231116_LT004 RML_16112023172434.pdf\n",
      "Wrote all_LT_new_trial/20231116_LT004 RML_001.fcs\n",
      "No file for LT004‑bal3_sort_report (HTTP 400)\n",
      "No file for LT004‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT004‑bal4_sort_report (HTTP 400)\n",
      "No file for LT004‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20221129_LT005 RML_29112022172607.pdf\n",
      "Wrote all_LT_new_trial/20221129_LT005 RML_001.fcs\n",
      "No file for LT005‑bal2_sort_report (HTTP 400)\n",
      "No file for LT005‑bal2_sort_fcs (HTTP 400)\n",
      "No file for LT005‑bal3_sort_report (HTTP 400)\n",
      "No file for LT005‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT005‑bal4_sort_report (HTTP 400)\n",
      "No file for LT005‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20210923_LT006_LUL_23092021173352.pdf\n",
      "Wrote all_LT_new_trial/20210923_LT006_LUL_001.fcs\n",
      "Wrote all_LT_new_trial/20210923_LT006_RML_23092021174643.pdf\n",
      "Wrote all_LT_new_trial/20210923_LT006_RML_001.fcs\n",
      "No file for LT006‑bal3_sort_report (HTTP 400)\n",
      "No file for LT006‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT006‑bal4_sort_report (HTTP 400)\n",
      "No file for LT006‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20230721_LT007 LUL_21072023155920.pdf\n",
      "Wrote all_LT_new_trial/20230721_LT007 LUL_001.fcs\n",
      "Wrote all_LT_new_trial/20230721_LT007 RML_21072023160628.pdf\n",
      "Wrote all_LT_new_trial/20230721_LT007 RML_001.fcs\n",
      "No file for LT007‑bal3_sort_report (HTTP 400)\n",
      "No file for LT007‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT007‑bal4_sort_report (HTTP 400)\n",
      "No file for LT007‑bal4_sort_fcs (HTTP 400)\n",
      "No file for LT008‑bal1_sort_report (HTTP 400)\n",
      "No file for LT008‑bal1_sort_fcs (HTTP 400)\n",
      "No file for LT008‑bal2_sort_report (HTTP 400)\n",
      "No file for LT008‑bal2_sort_fcs (HTTP 400)\n",
      "No file for LT008‑bal3_sort_report (HTTP 400)\n",
      "No file for LT008‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT008‑bal4_sort_report (HTTP 400)\n",
      "No file for LT008‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20211014_LT009 LUL_14102021164315.pdf\n",
      "Wrote all_LT_new_trial/20211014_LT009 LUL_001.fcs\n",
      "Wrote all_LT_new_trial/20211014_LT009 RML_14102021162415.pdf\n",
      "Wrote all_LT_new_trial/20211014_LT009 RML_001.fcs\n",
      "No file for LT009‑bal3_sort_report (HTTP 400)\n",
      "No file for LT009‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT009‑bal4_sort_report (HTTP 400)\n",
      "No file for LT009‑bal4_sort_fcs (HTTP 400)\n",
      "No file for LT010‑bal1_sort_report (HTTP 400)\n",
      "No file for LT010‑bal1_sort_fcs (HTTP 400)\n",
      "No file for LT010‑bal2_sort_report (HTTP 400)\n",
      "No file for LT010‑bal2_sort_fcs (HTTP 400)\n",
      "No file for LT010‑bal3_sort_report (HTTP 400)\n",
      "No file for LT010‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT010‑bal4_sort_report (HTTP 400)\n",
      "No file for LT010‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20210909_LT011_RML_09092021165508.pdf\n",
      "Wrote all_LT_new_trial/20210909_LT011_RML_001.fcs\n",
      "No file for LT011‑bal2_sort_report (HTTP 400)\n",
      "No file for LT011‑bal2_sort_fcs (HTTP 400)\n",
      "No file for LT011‑bal3_sort_report (HTTP 400)\n",
      "No file for LT011‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT011‑bal4_sort_report (HTTP 400)\n",
      "No file for LT011‑bal4_sort_fcs (HTTP 400)\n",
      "No file for LT012‑bal1_sort_report (HTTP 400)\n",
      "No file for LT012‑bal1_sort_fcs (HTTP 400)\n",
      "No file for LT012‑bal2_sort_report (HTTP 400)\n",
      "No file for LT012‑bal2_sort_fcs (HTTP 400)\n",
      "No file for LT012‑bal3_sort_report (HTTP 400)\n",
      "No file for LT012‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT012‑bal4_sort_report (HTTP 400)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No file for LT012‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20240104_LT013 LUL_04012024162148.pdf\n",
      "Wrote all_LT_new_trial/20240104_LT013 LUL_001.fcs\n",
      "Wrote all_LT_new_trial/20240104_LT013 RML_04012024162857.pdf\n",
      "Wrote all_LT_new_trial/20240104_LT013 RML_001.fcs\n",
      "No file for LT013‑bal3_sort_report (HTTP 400)\n",
      "No file for LT013‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT013‑bal4_sort_report (HTTP 400)\n",
      "No file for LT013‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20210805_LT014_05082021175022.pdf\n",
      "Wrote all_LT_new_trial/20210805_LT014_001.fcs\n",
      "No file for LT014‑bal2_sort_report (HTTP 400)\n",
      "No file for LT014‑bal2_sort_fcs (HTTP 400)\n",
      "No file for LT014‑bal3_sort_report (HTTP 400)\n",
      "No file for LT014‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT014‑bal4_sort_report (HTTP 400)\n",
      "No file for LT014‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20210805_LT015_05082021180626.pdf\n",
      "Wrote all_LT_new_trial/20210805_LT015_001.fcs\n",
      "No file for LT015‑bal2_sort_report (HTTP 400)\n",
      "No file for LT015‑bal2_sort_fcs (HTTP 400)\n",
      "No file for LT015‑bal3_sort_report (HTTP 400)\n",
      "No file for LT015‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT015‑bal4_sort_report (HTTP 400)\n",
      "No file for LT015‑bal4_sort_fcs (HTTP 400)\n",
      "No file for LT016‑bal1_sort_report (HTTP 400)\n",
      "No file for LT016‑bal1_sort_fcs (HTTP 400)\n",
      "No file for LT016‑bal2_sort_report (HTTP 400)\n",
      "No file for LT016‑bal2_sort_fcs (HTTP 400)\n",
      "No file for LT016‑bal3_sort_report (HTTP 400)\n",
      "No file for LT016‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT016‑bal4_sort_report (HTTP 400)\n",
      "No file for LT016‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20211111_LT017 LUL_11112021170106.pdf\n",
      "Wrote all_LT_new_trial/20211111_LT017 LUL_001.fcs\n",
      "Wrote all_LT_new_trial/20211111_LT017 RML_11112021171101.pdf\n",
      "Wrote all_LT_new_trial/20211111_LT017 RML_001.fcs\n",
      "No file for LT017‑bal3_sort_report (HTTP 400)\n",
      "No file for LT017‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT017‑bal4_sort_report (HTTP 400)\n",
      "No file for LT017‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20210819_LT018 LUL_19082021164530.pdf\n",
      "Wrote all_LT_new_trial/20210819_LT018 LUL_001.fcs\n",
      "Wrote all_LT_new_trial/20210819_LT018 RML_19082021170736.pdf\n",
      "Wrote all_LT_new_trial/20210819_LT018 RML_001.fcs\n",
      "No file for LT018‑bal3_sort_report (HTTP 400)\n",
      "No file for LT018‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT018‑bal4_sort_report (HTTP 400)\n",
      "No file for LT018‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20220310_CLAD77_2421_10032022133233.pdf\n",
      "Wrote all_LT_new_trial/20220310_CLAD77_2421_001.fcs\n",
      "Wrote all_LT_new_trial/20220310_CLAD77_2411_10032022132115.pdf\n",
      "Wrote all_LT_new_trial/20220310_CLAD77_2411_001.fcs\n",
      "No file for LT019‑bal3_sort_report (HTTP 400)\n",
      "No file for LT019‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT019‑bal4_sort_report (HTTP 400)\n",
      "No file for LT019‑bal4_sort_fcs (HTTP 400)\n",
      "No file for LT020‑bal1_sort_report (HTTP 400)\n",
      "No file for LT020‑bal1_sort_fcs (HTTP 400)\n",
      "No file for LT020‑bal2_sort_report (HTTP 400)\n",
      "No file for LT020‑bal2_sort_fcs (HTTP 400)\n",
      "No file for LT020‑bal3_sort_report (HTTP 400)\n",
      "No file for LT020‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT020‑bal4_sort_report (HTTP 400)\n",
      "No file for LT020‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20210819_LT021 LUL_19082021173155.pdf\n",
      "Wrote all_LT_new_trial/20210819_LT021 LUL_001.fcs\n",
      "Wrote all_LT_new_trial/20210819_LT021 RML_19082021175011.pdf\n",
      "Wrote all_LT_new_trial/20210819_LT021 RML_001.fcs\n",
      "No file for LT021‑bal3_sort_report (HTTP 400)\n",
      "No file for LT021‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT021‑bal4_sort_report (HTTP 400)\n",
      "No file for LT021‑bal4_sort_fcs (HTTP 400)\n",
      "No file for LT022‑bal1_sort_report (HTTP 400)\n",
      "No file for LT022‑bal1_sort_fcs (HTTP 400)\n",
      "No file for LT022‑bal2_sort_report (HTTP 400)\n",
      "No file for LT022‑bal2_sort_fcs (HTTP 400)\n",
      "No file for LT022‑bal3_sort_report (HTTP 400)\n",
      "No file for LT022‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT022‑bal4_sort_report (HTTP 400)\n",
      "No file for LT022‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20210812_LT023 BILAT_12082021164832.pdf\n",
      "Wrote all_LT_new_trial/20210812_LT023 BILAT_001.fcs\n",
      "Wrote all_LT_new_trial/20210812_LT023 LUL_12082021170132.pdf\n",
      "No file for LT023‑bal2_sort_fcs (HTTP 400)\n",
      "No file for LT023‑bal3_sort_report (HTTP 400)\n",
      "No file for LT023‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT023‑bal4_sort_report (HTTP 400)\n",
      "No file for LT023‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20210820_LT024 LUL_20082021164408.pdf\n",
      "Wrote all_LT_new_trial/20210820_LT024 LUL_001.fcs\n",
      "Wrote all_LT_new_trial/20210820_LT024 RML_20082021170751.pdf\n",
      "Wrote all_LT_new_trial/20210820_LT024 RML_001.fcs\n",
      "No file for LT024‑bal3_sort_report (HTTP 400)\n",
      "No file for LT024‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT024‑bal4_sort_report (HTTP 400)\n",
      "No file for LT024‑bal4_sort_fcs (HTTP 400)\n",
      "No file for LT025‑bal1_sort_report (HTTP 400)\n",
      "No file for LT025‑bal1_sort_fcs (HTTP 400)\n",
      "No file for LT025‑bal2_sort_report (HTTP 400)\n",
      "No file for LT025‑bal2_sort_fcs (HTTP 400)\n",
      "No file for LT025‑bal3_sort_report (HTTP 400)\n",
      "No file for LT025‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT025‑bal4_sort_report (HTTP 400)\n",
      "No file for LT025‑bal4_sort_fcs (HTTP 400)\n",
      "No file for LT026‑bal1_sort_report (HTTP 400)\n",
      "No file for LT026‑bal1_sort_fcs (HTTP 400)\n",
      "No file for LT026‑bal2_sort_report (HTTP 400)\n",
      "No file for LT026‑bal2_sort_fcs (HTTP 400)\n",
      "No file for LT026‑bal3_sort_report (HTTP 400)\n",
      "No file for LT026‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT026‑bal4_sort_report (HTTP 400)\n",
      "No file for LT026‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20210820_LT024 LUL_20082021164408.pdf\n",
      "Wrote all_LT_new_trial/20210820_LT024 LUL_001.fcs\n",
      "Wrote all_LT_new_trial/20210820_LT024 RML_20082021170751.pdf\n",
      "Wrote all_LT_new_trial/20210820_LT024 RML_001.fcs\n",
      "No file for LT027‑bal3_sort_report (HTTP 400)\n",
      "No file for LT027‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT027‑bal4_sort_report (HTTP 400)\n",
      "No file for LT027‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20210729_LT028_29072021184038.pdf\n",
      "Wrote all_LT_new_trial/20210729_LT028_001.fcs\n",
      "No file for LT028‑bal2_sort_report (HTTP 400)\n",
      "No file for LT028‑bal2_sort_fcs (HTTP 400)\n",
      "No file for LT028‑bal3_sort_report (HTTP 400)\n",
      "No file for LT028‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT028‑bal4_sort_report (HTTP 400)\n",
      "No file for LT028‑bal4_sort_fcs (HTTP 400)\n",
      "No file for LT029‑bal1_sort_report (HTTP 400)\n",
      "No file for LT029‑bal1_sort_fcs (HTTP 400)\n",
      "No file for LT029‑bal2_sort_report (HTTP 400)\n",
      "No file for LT029‑bal2_sort_fcs (HTTP 400)\n",
      "No file for LT029‑bal3_sort_report (HTTP 400)\n",
      "No file for LT029‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT029‑bal4_sort_report (HTTP 400)\n",
      "No file for LT029‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20230803_LT030 LUL_03082023173749.pdf\n",
      "Wrote all_LT_new_trial/20230803_LT030 LUL_001.fcs\n",
      "Wrote all_LT_new_trial/20230803_LT030 RML_03082023174622.pdf\n",
      "Wrote all_LT_new_trial/20230803_LT030 RML_001.fcs\n",
      "No file for LT030‑bal3_sort_report (HTTP 400)\n",
      "No file for LT030‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT030‑bal4_sort_report (HTTP 400)\n",
      "No file for LT030‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20220606_LT031 LUL_06062022163921.pdf\n",
      "Wrote all_LT_new_trial/20220606_LT031 LUL_001.fcs\n",
      "Wrote all_LT_new_trial/20220606_LT031 RML_06062022164626.pdf\n",
      "Wrote all_LT_new_trial/20220606_LT031 RML_001.fcs\n",
      "No file for LT031‑bal3_sort_report (HTTP 400)\n",
      "No file for LT031‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT031‑bal4_sort_report (HTTP 400)\n",
      "No file for LT031‑bal4_sort_fcs (HTTP 400)\n",
      "No file for LT032‑bal1_sort_report (HTTP 400)\n",
      "No file for LT032‑bal1_sort_fcs (HTTP 400)\n",
      "No file for LT032‑bal2_sort_report (HTTP 400)\n",
      "No file for LT032‑bal2_sort_fcs (HTTP 400)\n",
      "No file for LT032‑bal3_sort_report (HTTP 400)\n",
      "No file for LT032‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT032‑bal4_sort_report (HTTP 400)\n",
      "No file for LT032‑bal4_sort_fcs (HTTP 400)\n",
      "No file for LT033‑bal1_sort_report (HTTP 400)\n",
      "No file for LT033‑bal1_sort_fcs (HTTP 400)\n",
      "No file for LT033‑bal2_sort_report (HTTP 400)\n",
      "No file for LT033‑bal2_sort_fcs (HTTP 400)\n",
      "No file for LT033‑bal3_sort_report (HTTP 400)\n",
      "No file for LT033‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT033‑bal4_sort_report (HTTP 400)\n",
      "No file for LT033‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20220811_LT034 LUL_11082022160747.pdf\n",
      "No file for LT034‑bal1_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20220811_LT034 RML_11082022163550.pdf\n",
      "No file for LT034‑bal2_sort_fcs (HTTP 400)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No file for LT034‑bal3_sort_report (HTTP 400)\n",
      "No file for LT034‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT034‑bal4_sort_report (HTTP 400)\n",
      "No file for LT034‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20210812_LT035 LUL_12082021171335.pdf\n",
      "Wrote all_LT_new_trial/20210812_LT035 LUL_001.fcs\n",
      "No file for LT035‑bal2_sort_report (HTTP 400)\n",
      "No file for LT035‑bal2_sort_fcs (HTTP 400)\n",
      "No file for LT035‑bal3_sort_report (HTTP 400)\n",
      "No file for LT035‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT035‑bal4_sort_report (HTTP 400)\n",
      "No file for LT035‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20230727_LT036 LUL_27072023184634.pdf\n",
      "Wrote all_LT_new_trial/20230727_LT036 LUL_001.fcs\n",
      "Wrote all_LT_new_trial/20230727_LT036 RML_27072023192627.pdf\n",
      "Wrote all_LT_new_trial/20230727_LT036 RML_001.fcs\n",
      "No file for LT036‑bal3_sort_report (HTTP 400)\n",
      "No file for LT036‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT036‑bal4_sort_report (HTTP 400)\n",
      "No file for LT036‑bal4_sort_fcs (HTTP 400)\n",
      "No file for LT037‑bal1_sort_report (HTTP 400)\n",
      "No file for LT037‑bal1_sort_fcs (HTTP 400)\n",
      "No file for LT037‑bal2_sort_report (HTTP 400)\n",
      "No file for LT037‑bal2_sort_fcs (HTTP 400)\n",
      "No file for LT037‑bal3_sort_report (HTTP 400)\n",
      "No file for LT037‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT037‑bal4_sort_report (HTTP 400)\n",
      "No file for LT037‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20220916_LT038 LUL_16092022180246.pdf\n",
      "Wrote all_LT_new_trial/20220916_LT038 LUL_001.fcs\n",
      "Wrote all_LT_new_trial/20220916_LT038 RML_16092022181359.pdf\n",
      "Wrote all_LT_new_trial/20220916_LT038 RML_001.fcs\n",
      "No file for LT038‑bal3_sort_report (HTTP 400)\n",
      "No file for LT038‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT038‑bal4_sort_report (HTTP 400)\n",
      "No file for LT038‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20220922_LT039 LUL_22092022163707.pdf\n",
      "Wrote all_LT_new_trial/20220922_LT039 LUL_001.fcs\n",
      "Wrote all_LT_new_trial/20220922_LT039 RML_22092022164756.pdf\n",
      "Wrote all_LT_new_trial/20220922_LT039 RML_001.fcs\n",
      "No file for LT039‑bal3_sort_report (HTTP 400)\n",
      "No file for LT039‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT039‑bal4_sort_report (HTTP 400)\n",
      "No file for LT039‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20220811_LT040 LUL_11082022162052.pdf\n",
      "No file for LT040‑bal1_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20220811_LT040 RML_11082022164701.pdf\n",
      "No file for LT040‑bal2_sort_fcs (HTTP 400)\n",
      "No file for LT040‑bal3_sort_report (HTTP 400)\n",
      "No file for LT040‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT040‑bal4_sort_report (HTTP 400)\n",
      "No file for LT040‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20241220_LT041 LUL_20122024171502.pdf\n",
      "Wrote all_LT_new_trial/20241220_LT041 LUL_001.fcs\n",
      "Wrote all_LT_new_trial/20241220_LT041 RML_20122024172353.pdf\n",
      "Wrote all_LT_new_trial/20241220_LT041 RML_001.fcs\n",
      "No file for LT041‑bal3_sort_report (HTTP 400)\n",
      "No file for LT041‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT041‑bal4_sort_report (HTTP 400)\n",
      "No file for LT041‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20220922_LT042 LUL_22092022165703.pdf\n",
      "Wrote all_LT_new_trial/20220922_LT042 LUL_001.fcs\n",
      "Wrote all_LT_new_trial/20220922_LT042 RML_22092022170916.pdf\n",
      "Wrote all_LT_new_trial/20220922_LT042 RML_001.fcs\n",
      "No file for LT042‑bal3_sort_report (HTTP 400)\n",
      "No file for LT042‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT042‑bal4_sort_report (HTTP 400)\n",
      "No file for LT042‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20220804_LT043 LUL_04082022151040.pdf\n",
      "Wrote all_LT_new_trial/20220804_LT043 LUL_001.fcs\n",
      "Wrote all_LT_new_trial/20220804_LT043 RML_04082022152542.pdf\n",
      "Wrote all_LT_new_trial/20220804_LT043 RML_001.fcs\n",
      "No file for LT043‑bal3_sort_report (HTTP 400)\n",
      "No file for LT043‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT043‑bal4_sort_report (HTTP 400)\n",
      "No file for LT043‑bal4_sort_fcs (HTTP 400)\n",
      "No file for LT044‑bal1_sort_report (HTTP 400)\n",
      "No file for LT044‑bal1_sort_fcs (HTTP 400)\n",
      "No file for LT044‑bal2_sort_report (HTTP 400)\n",
      "No file for LT044‑bal2_sort_fcs (HTTP 400)\n",
      "No file for LT044‑bal3_sort_report (HTTP 400)\n",
      "No file for LT044‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT044‑bal4_sort_report (HTTP 400)\n",
      "No file for LT044‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20230831_LT045 LUL_31082023174551.pdf\n",
      "Wrote all_LT_new_trial/20230831_LT045 LUL_001.fcs\n",
      "Wrote all_LT_new_trial/20230831_LT045 RML_31082023175648.pdf\n",
      "Wrote all_LT_new_trial/20230831_LT045 RML_001.fcs\n",
      "No file for LT045‑bal3_sort_report (HTTP 400)\n",
      "No file for LT045‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT045‑bal4_sort_report (HTTP 400)\n",
      "No file for LT045‑bal4_sort_fcs (HTTP 400)\n",
      "No file for LT046‑bal1_sort_report (HTTP 400)\n",
      "No file for LT046‑bal1_sort_fcs (HTTP 400)\n",
      "No file for LT046‑bal2_sort_report (HTTP 400)\n",
      "No file for LT046‑bal2_sort_fcs (HTTP 400)\n",
      "No file for LT046‑bal3_sort_report (HTTP 400)\n",
      "No file for LT046‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT046‑bal4_sort_report (HTTP 400)\n",
      "No file for LT046‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20220728_LT047 LUL_28072022152031.pdf\n",
      "Wrote all_LT_new_trial/20220728_LT047 LUL_001.fcs\n",
      "Wrote all_LT_new_trial/20220728_LT047 RML_28072022153131.pdf\n",
      "No file for LT047‑bal2_sort_fcs (HTTP 400)\n",
      "No file for LT047‑bal3_sort_report (HTTP 400)\n",
      "No file for LT047‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT047‑bal4_sort_report (HTTP 400)\n",
      "No file for LT047‑bal4_sort_fcs (HTTP 400)\n",
      "No file for LT048‑bal1_sort_report (HTTP 400)\n",
      "No file for LT048‑bal1_sort_fcs (HTTP 400)\n",
      "No file for LT048‑bal2_sort_report (HTTP 400)\n",
      "No file for LT048‑bal2_sort_fcs (HTTP 400)\n",
      "No file for LT048‑bal3_sort_report (HTTP 400)\n",
      "No file for LT048‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT048‑bal4_sort_report (HTTP 400)\n",
      "No file for LT048‑bal4_sort_fcs (HTTP 400)\n",
      "No file for LT049‑bal1_sort_report (HTTP 400)\n",
      "No file for LT049‑bal1_sort_fcs (HTTP 400)\n",
      "No file for LT049‑bal2_sort_report (HTTP 400)\n",
      "No file for LT049‑bal2_sort_fcs (HTTP 400)\n",
      "No file for LT049‑bal3_sort_report (HTTP 400)\n",
      "No file for LT049‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT049‑bal4_sort_report (HTTP 400)\n",
      "No file for LT049‑bal4_sort_fcs (HTTP 400)\n",
      "No file for LT050‑bal1_sort_report (HTTP 400)\n",
      "No file for LT050‑bal1_sort_fcs (HTTP 400)\n",
      "No file for LT050‑bal2_sort_report (HTTP 400)\n",
      "No file for LT050‑bal2_sort_fcs (HTTP 400)\n",
      "No file for LT050‑bal3_sort_report (HTTP 400)\n",
      "No file for LT050‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT050‑bal4_sort_report (HTTP 400)\n",
      "No file for LT050‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20220217_LT051 LUL_17022022164627.pdf\n",
      "Wrote all_LT_new_trial/20220217_LT051 LUL_001.fcs\n",
      "Wrote all_LT_new_trial/20220217_LT051 RML_17022022165541.pdf\n",
      "Wrote all_LT_new_trial/20220217_LT051 RML_001.fcs\n",
      "No file for LT051‑bal3_sort_report (HTTP 400)\n",
      "No file for LT051‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT051‑bal4_sort_report (HTTP 400)\n",
      "No file for LT051‑bal4_sort_fcs (HTTP 400)\n",
      "No file for LT052‑bal1_sort_report (HTTP 400)\n",
      "No file for LT052‑bal1_sort_fcs (HTTP 400)\n",
      "No file for LT052‑bal2_sort_report (HTTP 400)\n",
      "No file for LT052‑bal2_sort_fcs (HTTP 400)\n",
      "No file for LT052‑bal3_sort_report (HTTP 400)\n",
      "No file for LT052‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT052‑bal4_sort_report (HTTP 400)\n",
      "No file for LT052‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20220303_LT053 LUL_03032022164713.pdf\n",
      "Wrote all_LT_new_trial/20220303_LT053 LUL_001.fcs\n",
      "Wrote all_LT_new_trial/20220303_LT053 RML_03032022165027.pdf\n",
      "Wrote all_LT_new_trial/20220303_LT053 RML_001.fcs\n",
      "No file for LT053‑bal3_sort_report (HTTP 400)\n",
      "No file for LT053‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT053‑bal4_sort_report (HTTP 400)\n",
      "No file for LT053‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20220505_LT054 LUL_05052022160057.pdf\n",
      "Wrote all_LT_new_trial/20220505_LT054 LUL_001.fcs\n",
      "Wrote all_LT_new_trial/20220505_LT054 RML_05052022160806.pdf\n",
      "Wrote all_LT_new_trial/20220505_LT054 RML_001.fcs\n",
      "No file for LT054‑bal3_sort_report (HTTP 400)\n",
      "No file for LT054‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT054‑bal4_sort_report (HTTP 400)\n",
      "No file for LT054‑bal4_sort_fcs (HTTP 400)\n",
      "No file for LT055‑bal1_sort_report (HTTP 400)\n",
      "No file for LT055‑bal1_sort_fcs (HTTP 400)\n",
      "No file for LT055‑bal2_sort_report (HTTP 400)\n",
      "No file for LT055‑bal2_sort_fcs (HTTP 400)\n",
      "No file for LT055‑bal3_sort_report (HTTP 400)\n",
      "No file for LT055‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT055‑bal4_sort_report (HTTP 400)\n",
      "No file for LT055‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20221014_LT056,3f,,3f,LUL_14102022172730.pdf\n",
      "Wrote all_LT_new_trial/20221014_LT056,3f,,3f,LUL_001.fcs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote all_LT_new_trial/20221014_LT056,3f,,3f,RML_14102022173443.pdf\n",
      "Wrote all_LT_new_trial/20221014_LT056,3f,,3f,RML_001.fcs\n",
      "No file for LT056‑bal3_sort_report (HTTP 400)\n",
      "No file for LT056‑bal3_sort_fcs (HTTP 400)\n",
      "No file for LT056‑bal4_sort_report (HTTP 400)\n",
      "No file for LT056‑bal4_sort_fcs (HTTP 400)\n",
      "Wrote all_LT_new_trial/20220407_LT057 LUL_07042022160949.pdf\n",
      "Wrote all_LT_new_trial/20220407_LT057 LUL_001.fcs\n",
      "Wrote all_LT_new_trial/20220407_LT057 RML_07042022161913.pdf\n",
      "Wrote all_LT_new_trial/20220407_LT057 RML_001.fcs\n",
      "No file for LT057‑bal3_sort_report (HTTP 400)\n",
      "No file for LT057‑bal3_sort_fcs (HTTP 400)\n"
     ]
    }
   ],
   "source": [
    "api_url = \"https://redcap.nubic.northwestern.edu/redcap/api/\"\n",
    "api_token = \"BE24D55CBF39107AD9CA7EB215E9E2E5\"\n",
    "recs = requests.post(api_url, #get all the records names\n",
    "  data={\n",
    "    'token':   api_token,\n",
    "    'content': 'record',\n",
    "    'format':  'json'\n",
    "  }\n",
    ").json()\n",
    "\n",
    "print(f\"Got {len(recs)} records\\n\")\n",
    "\n",
    "\n",
    "# print(\"First 3 records preview:\")\n",
    "# print(json.dumps(recs[:3], indent=2)) \n",
    "\n",
    "record_ids = sorted(set([r['record_id'] for r in recs]))\n",
    "print(record_ids) #onle keep unique record names\n",
    "\n",
    "meta = requests.post(api_url, data={\n",
    "  'token': api_token,\n",
    "  'content': 'metadata',\n",
    "  'format': 'json'\n",
    "}).json()\n",
    "\n",
    "\n",
    "file_fields = [m['field_name']\n",
    "               for m in meta\n",
    "               if m['field_type']=='file']\n",
    "print(\"File‑upload fields:\", file_fields)\n",
    "\n",
    "\n",
    "folder = 'all_LT_new_trial'\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "file_fields_project_specific = ['bal1_sort_report', 'bal1_sort_fcs', 'bal2_sort_report', 'bal2_sort_fcs', \n",
    "                                'bal3_sort_report', 'bal3_sort_fcs', 'bal4_sort_report', 'bal4_sort_fcs']  \n",
    "\n",
    "for rec in record_ids: #for each record id pull the file\n",
    "    for fld in file_fields_project_specific:\n",
    "        payload = {\n",
    "            'token':   api_token,\n",
    "            'content': 'file',\n",
    "            'action':  'export',\n",
    "            'record':  rec,\n",
    "            'field':   fld,            # one field per request\n",
    "        }\n",
    "        r = requests.post(api_url, data=payload)\n",
    "        if r.status_code == 200 and r.content:\n",
    "            ctype = r.headers.get('Content-Type', '')\n",
    "            if 'text/xml' in ctype:\n",
    "                print(f\"No file for {rec}-{fld}, got XML error\")\n",
    "                continue\n",
    "\n",
    "            # extract the name=\"...\" parameter\n",
    "            m = re.search(r'name=\"([^\"]+)\"', ctype)\n",
    "            filename = m.group(1)   # e.g. \"20210923_LT001_LUL_23092021171938.pdf\"\n",
    "            # write out the file\n",
    "            outpath = os.path.join(folder, filename)\n",
    "            with open(outpath, 'wb') as f:\n",
    "                f.write(r.content)\n",
    "            print(f\"Wrote {outpath}\")\n",
    "        else:\n",
    "             print(f\"No file for {rec}‑{fld} (HTTP {r.status_code})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7860dad4",
   "metadata": {},
   "source": [
    "Some of the files do not come from RedCap but from OneDrive, so they have to be moved to the directory where the following jupyter notebook is located. These folders have to be parsed through using parse_fcs_folder, and recorded in the inventory. The function below assume that the parent folder had subfolders and uses metadata from those subfolders to collect the data into the inventory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05efed91-6e82-472c-9d86-c738571ec95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fcs_folder(main_folder):\n",
    "    study_condition_map = {\n",
    "        'PASC': 'long COVID (Post-acute sequelae of SARS-CoV-2 infection)',\n",
    "        'Abbvie': 'scleroderma',\n",
    "        'Duke_ozone': 'control samples, healthy volunteers',\n",
    "        'WashU_BAL': 'pneumonia',\n",
    "        'SCRIPT': 'pneumonia'\n",
    "    } #the folders names should be here\n",
    "    #add more if needed\n",
    "\n",
    "    records = []\n",
    "\n",
    "    for subfolder in os.listdir(main_folder):\n",
    "        subfolder_path = os.path.join(main_folder, subfolder)\n",
    "        if not os.path.isdir(subfolder_path):\n",
    "            continue\n",
    "\n",
    "        study_name = os.path.basename(main_folder)\n",
    "        condition = study_condition_map.get(study_name, 'Unknown')\n",
    "\n",
    "        fcs_files = [f for f in os.listdir(subfolder_path) if f.endswith('.fcs')]\n",
    "        pdf_files = [f for f in os.listdir(subfolder_path) if f.endswith('.pdf')]\n",
    "\n",
    "        for fcs in fcs_files:\n",
    "            fcs_parts = fcs.split('_')\n",
    "            fcs_key = '_'.join(fcs_parts[:2]) if len(fcs_parts) >= 2 else fcs_parts[0]\n",
    "            base = fcs_parts[0]\n",
    "            date_str = base[:8]\n",
    "            year = date_str[:4]\n",
    "            month = date_str[4:6]\n",
    "\n",
    "            matched_pdfs = [\n",
    "                pdf for pdf in pdf_files if pdf.startswith(fcs_key)\n",
    "            ]\n",
    "\n",
    "            records.append({\n",
    "                'Study': study_name,\n",
    "                'Disease/Condition': condition,\n",
    "                'Subfolder': subfolder,\n",
    "                'FCS File': fcs,\n",
    "                'Year': year,\n",
    "                'Month': month,\n",
    "                'Is there a PDF report?': bool(matched_pdfs),\n",
    "                '# of PDF reports associated with fcs file': len(matched_pdfs),\n",
    "                'PDF reports names:': ', '.join(matched_pdfs)\n",
    "                \n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ab8bc7",
   "metadata": {},
   "source": [
    "Some of the folders dont have the subfolders, so we need to use a different function for them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b5cd4093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fcs_folder_no_subfolders(folder):\n",
    "    study_condition_map = {\n",
    "        'PASC': 'long COVID (Post-acute sequelae of SARS-CoV-2 infection)',\n",
    "        'Abbvie': 'scleroderma',\n",
    "        'Duke_ozone': 'control samples, healthy volunteers',\n",
    "        'WashU_BAL': 'pneumonia',\n",
    "        'SCRIPT': 'pneumonia',\n",
    "        \"LungTransplant\":\"pulmonary fibrosis\"\n",
    "    }\n",
    "\n",
    "    records = []\n",
    "\n",
    "\n",
    "    study_name = os.path.basename(folder)\n",
    "    condition = study_condition_map.get(study_name, 'Unknown')\n",
    "\n",
    "    fcs_files = [f for f in os.listdir(folder) if f.endswith('.fcs')]\n",
    "    pdf_files = [f for f in os.listdir(folder) if f.endswith('.pdf')]\n",
    "\n",
    "    for fcs in fcs_files:\n",
    "        fcs_parts = fcs.split('_')\n",
    "        fcs_key = '_'.join(fcs_parts[:2]) if len(fcs_parts) >= 2 else fcs_parts[0]\n",
    "        base = fcs_parts[0]\n",
    "        date_str = base[:8]\n",
    "        year = date_str[:4]\n",
    "        month = date_str[4:6]\n",
    "\n",
    "        matched_pdfs = [\n",
    "            pdf for pdf in pdf_files if pdf.startswith(fcs_key)\n",
    "        ]\n",
    "\n",
    "        records.append({\n",
    "            'Study': study_name,\n",
    "            'Disease/Condition': condition,\n",
    "            'Subfolder': f\"{os.path.join(os.getcwd(),folder)}\",\n",
    "            'FCS File': fcs,\n",
    "            'Year': year,\n",
    "            'Month': month,\n",
    "            'Is there a PDF report?': bool(matched_pdfs),\n",
    "            '# of PDF reports associated with fcs file': len(matched_pdfs),\n",
    "            'PDF reports names:': ', '.join(matched_pdfs)\n",
    "\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4124f17d-6843-434e-b0b0-c276af5cc1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/gpfs/projects/b1042/MisharinLab/anna'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08af1981-16c7-4f16-a057-a1d8c7108724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pasc = parse_fcs_folder('/mnt/c/Users/Anechka/Documents/Northwestern/files/Sasha_one_drive/PASC')\n",
    "\n",
    "# pasc\n",
    "\n",
    "# abbvie = parse_fcs_folder('/mnt/c/Users/Anechka/Documents/Northwestern/files/Sasha_one_drive/Abbvie')\n",
    "\n",
    "# abbvie\n",
    "\n",
    "# duke = parse_fcs_folder('/mnt/c/Users/Anechka/Documents/Northwestern/files/Sasha_one_drive/Duke_ozone')\n",
    "\n",
    "# duke\n",
    "\n",
    "# wash = parse_fcs_folder('/mnt/c/Users/Anechka/Documents/Northwestern/files/Sasha_one_drive/WashU_BAL')\n",
    "\n",
    "# wash\n",
    "\n",
    "# concatenated = pd.concat([pasc,abbvie,wash,duke], ignore_index = True)\n",
    "\n",
    "# filename = \"one_drive_inventory.csv\"\n",
    "# path = '/mnt/c/Users/Anechka/Documents/Northwestern/files/Sasha_one_drive'\n",
    "# csv_ed = concatenated.to_csv(os.path.join(path,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "72812bc0-1303-4a68-aa4f-2b706d167dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Study</th>\n",
       "      <th>Disease/Condition</th>\n",
       "      <th>Subfolder</th>\n",
       "      <th>FCS File</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Is there a PDF report?</th>\n",
       "      <th># of PDF reports associated with fcs file</th>\n",
       "      <th>PDF reports names:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SCRIPT</td>\n",
       "      <td>pneumonia</td>\n",
       "      <td>2022_08</td>\n",
       "      <td>20220818_1647-BAL-00_001.fcs</td>\n",
       "      <td>2022</td>\n",
       "      <td>08</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>20220818_1647-BAL-00_18082022141905.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SCRIPT</td>\n",
       "      <td>pneumonia</td>\n",
       "      <td>2022_08</td>\n",
       "      <td>20220802_1644-BAL-00_001.fcs</td>\n",
       "      <td>2022</td>\n",
       "      <td>08</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>20220802_1644-BAL-00_02082022173627.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCRIPT</td>\n",
       "      <td>pneumonia</td>\n",
       "      <td>2022_08</td>\n",
       "      <td>20220825_1650-BAL-07_001.fcs</td>\n",
       "      <td>2022</td>\n",
       "      <td>08</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>20220825_1650-BAL-07_31082022172231.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SCRIPT</td>\n",
       "      <td>pneumonia</td>\n",
       "      <td>2022_08</td>\n",
       "      <td>20220825_1628-BAL-90_001.fcs</td>\n",
       "      <td>2022</td>\n",
       "      <td>08</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>20220825_1628-BAL-90_31082022174051.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SCRIPT</td>\n",
       "      <td>pneumonia</td>\n",
       "      <td>2022_08</td>\n",
       "      <td>20220818_1648-BAL-00_001.fcs</td>\n",
       "      <td>2022</td>\n",
       "      <td>08</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>20220818_1648-BAL-00_18082022143036.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Study Disease/Condition Subfolder                      FCS File  Year  \\\n",
       "0  SCRIPT         pneumonia   2022_08  20220818_1647-BAL-00_001.fcs  2022   \n",
       "1  SCRIPT         pneumonia   2022_08  20220802_1644-BAL-00_001.fcs  2022   \n",
       "2  SCRIPT         pneumonia   2022_08  20220825_1650-BAL-07_001.fcs  2022   \n",
       "3  SCRIPT         pneumonia   2022_08  20220825_1628-BAL-90_001.fcs  2022   \n",
       "4  SCRIPT         pneumonia   2022_08  20220818_1648-BAL-00_001.fcs  2022   \n",
       "\n",
       "  Month  Is there a PDF report?  # of PDF reports associated with fcs file  \\\n",
       "0    08                    True                                          1   \n",
       "1    08                    True                                          1   \n",
       "2    08                    True                                          1   \n",
       "3    08                    True                                          1   \n",
       "4    08                    True                                          1   \n",
       "\n",
       "                        PDF reports names:  \n",
       "0  20220818_1647-BAL-00_18082022141905.pdf  \n",
       "1  20220802_1644-BAL-00_02082022173627.pdf  \n",
       "2  20220825_1650-BAL-07_31082022172231.pdf  \n",
       "3  20220825_1628-BAL-90_31082022174051.pdf  \n",
       "4  20220818_1648-BAL-00_18082022143036.pdf  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample run \n",
    "script_path = \"SCRIPT\" #indicate the name of the folder\n",
    "script = parse_fcs_folder(script_path) #parse throught the folder\n",
    "script.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0f3b43",
   "metadata": {},
   "source": [
    "Optional, but recommended: save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ae747238",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"csved_script.csv\" \n",
    "path = \".\"\n",
    "csv_ed = script.to_csv(os.path.join(path,filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0f8385",
   "metadata": {},
   "source": [
    "Some folders do not have the formating suitable to run function parse_fcs_files. Especially those that came from manually downloading from RedCap (SCRIPT or Abbvie). So they require renaming of the files. For renaming the files, we need the csv report that can map the names of the files to its nonconforming names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15652816",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_abbvie_report = \"AbbSSc (all available samples)/MolecularBiomarkersT-FSMFiles_DATA_2025-05-02_1210.csv\" #import the RedCap csv report\n",
    "root = Path('AbbSSc (all available samples)')\n",
    "abbvie_report = pd.read_csv(path_abbvie_report)\n",
    "abbvie_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a40bfcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Function to use for renaming Abbvie Files downloaded as Zip from the RedCap report\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def rename_abbvie_files(abbvie_report: pd.DataFrame,\n",
    "                        root: Path,\n",
    "                        dry_run: bool = True) -> None:\n",
    "    \"\"\"\n",
    "    Rename AbbVie BAL or whole‑blood files inside *root* based on filenames\n",
    "    stored in `abbvie_report`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    abbvie_report : pd.DataFrame\n",
    "        Must contain columns like 'bal1_sort_report', 'bal2_sort_fcs',\n",
    "        and 'whole_blood_fcs_1' plus the usual metadata columns:\n",
    "        'study_code' and 'redcap_event_name'.\n",
    "    root : pathlib.Path\n",
    "        Folder where the files live.\n",
    "    dry_run : bool, default True\n",
    "        If True, only prints what *would* happen.  Set False to rename for real.\n",
    "    \"\"\"\n",
    "    for _, row in abbvie_report.iterrows():\n",
    "        study = row.study_code\n",
    "        event = row.redcap_event_name\n",
    "\n",
    "        for bal in (1, 2):\n",
    "            for kind, ext in (('sort_report', 'pdf'),\n",
    "                              ('sort_fcs',    'fcs')):\n",
    "                # grab both “new” names\n",
    "                main_name  = str(row.get(f'bal{bal}_{kind}', '')).strip()\n",
    "                blood_name = str(row.get('whole_blood_fcs_1', '')).strip()\n",
    "\n",
    "                # (search‑pattern, target‑name) pairs\n",
    "                candidates = [\n",
    "                    (f\"{study}_{event}_bal{bal}_{kind}.{ext}\", main_name),\n",
    "                    (f\"{study}_{event}_whole_blood_fcs_1.{ext}\", blood_name)\n",
    "                ]\n",
    "\n",
    "                for stub, new_name in candidates:\n",
    "                    if not new_name or new_name.lower() == 'nan':\n",
    "                        continue  # nothing to rename to\n",
    "\n",
    "                    for old_path in root.glob(stub):\n",
    "                        new_path = root / new_name\n",
    "                        print(f\"{old_path.name}  →  {new_path.name}\")\n",
    "                        if not dry_run:\n",
    "                            old_path.rename(new_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec7b33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #to run uncomment this:\n",
    "\n",
    "root = Path(\"AbbSSc (all available samples)\") #specify your path\n",
    "rename_abbvie_files(abbvie_report, root)          # check if the renaming is correct - dry run\n",
    "rename_abbvie_files(abbvie_report, root, False)   # call this for complete renaming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dece84b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.rename('AbbSSc (all available samples)', \"Abbvie\") #rename the folder before running the parse function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "409ba7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "abbvie_2 = parse_fcs_folder_no_subfolders(\"Abbvie\")\n",
    "abbvie_2\n",
    "\n",
    "filename = \"csved_abbvie.csv\"\n",
    "path = \".\"\n",
    "csv_ed = abbvie_2.to_csv(os.path.join(path,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de788228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LT_report = pd.read_csv(\"LungTransplant/LungTransplantBiorep-FCSFiles_DATA_2025-05-08_1250.csv\")\n",
    "\n",
    "# LT_report.columns\n",
    "\n",
    "# root = Path(\"LungTransplant\")\n",
    "# def rename_LT_files(LT_report: pd.DataFrame,\n",
    "#                         root: Path,\n",
    "#                         dry_run: bool = True) -> None:\n",
    "#     \"\"\"\n",
    "#     Rename lung transplant files inside *root* based on filenames\n",
    "#     stored in `abbvie_report`.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     abbvie_report : pd.DataFrame\n",
    "#         Must contain columns like 'bal1_sort_report', 'bal2_sort_fcs',\n",
    "#         and 'whole_blood_fcs_1' plus the usual metadata columns:\n",
    "#         'study_code' and 'redcap_event_name'.\n",
    "#     root : pathlib.Path\n",
    "#         Folder where the files live.\n",
    "#     dry_run : bool, default True\n",
    "#         If True, only prints what *would* happen.  Set False to rename for real.\n",
    "#     \"\"\"\n",
    "#     for _, row in LT_report.iterrows():\n",
    "#         for bal in (1, 2):\n",
    "#             for kind, ext in (('sort_report', 'pdf'),\n",
    "#                               ('sort_fcs',    'fcs')):\n",
    "#                 # grab both “new” names\n",
    "#                 new_name  = str(row.get(f'bal{bal}_{kind}', '')).strip()\n",
    "#                 old_stab = f\"{row.record_id}_{row.redcap_repeat_instrument}_{row.redcap_repeat_instance}_bal{bal}_{kind}.{ext}\"\n",
    "#                 if new_name == 'nan':\n",
    "#                     continue\n",
    "#                 for old_path in root.glob(old_stab):\n",
    "#                     new_path = root / new_name\n",
    "#                     print(f\"{old_path.name}  →  {new_path.name}\")\n",
    "#                     if not dry_run:\n",
    "#                         old_path.rename(new_path)\n",
    "\n",
    "# root = Path(\"LungTransplant\")\n",
    "# rename_LT_files(LT_report,root,dry_run=False)\n",
    "\n",
    "# LT = parse_fcs_folder_no_subfolders(\"LungTransplant\")\n",
    "\n",
    "# LT.head()\n",
    "# filename = \"csved_LT.csv\"\n",
    "# path = \".\"\n",
    "# csv_ed = LT.to_csv(os.path.join(path,filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45031ec1",
   "metadata": {},
   "source": [
    "The script below is an example how to pull the csv report from the RedCap -> Optional "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "870f35a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Status: 200\n",
      "Saved report to report_LT_redcap.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "data = {\n",
    "    'token': 'BE24D55CBF39107AD9CA7EB215E9E2E5',\n",
    "    'content': 'report',\n",
    "    'format': 'csv',             \n",
    "    'report_id': '55649',\n",
    "    'csvDelimiter': ',',          \n",
    "    'rawOrLabel': 'raw',\n",
    "    'rawOrLabelHeaders': 'raw',\n",
    "    'exportCheckboxLabel': 'false'\n",
    "}\n",
    "\n",
    "r = requests.post('https://redcap.nubic.northwestern.edu/redcap/api/', data=data)\n",
    "print('HTTP Status:', r.status_code)\n",
    "\n",
    "if r.ok:\n",
    "    # write the CSV out to disk\n",
    "    with open('report_LT_redcap.csv', 'w', newline='') as f:\n",
    "        f.write(r.text)\n",
    "    print('Saved report to report_LT_redcap.csv')\n",
    "else:\n",
    "    print('Error:', r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4af6e24",
   "metadata": {},
   "source": [
    "Now, since we have assembled the entire inventory, we may now select at least 20 (choose your number) at random from each study. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf224783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Study</th>\n",
       "      <th>Disease/Condition</th>\n",
       "      <th>Subfolder</th>\n",
       "      <th>FCS File</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Is there a PDF report?</th>\n",
       "      <th># of PDF reports associated with fcs file</th>\n",
       "      <th>PDF reports names:</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PASC</td>\n",
       "      <td>long COVID (Post-acute sequelae of SARS-CoV-2 ...</td>\n",
       "      <td>20210413 PASC0019</td>\n",
       "      <td>20210413_LC001_BAL_01_001.fcs</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>20210413_LC001_BAL_01_13042021165347.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PASC</td>\n",
       "      <td>long COVID (Post-acute sequelae of SARS-CoV-2 ...</td>\n",
       "      <td>20210416 PASC0020</td>\n",
       "      <td>20210416_LC002_001.fcs</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>20210416_LC002_16042021164810.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PASC</td>\n",
       "      <td>long COVID (Post-acute sequelae of SARS-CoV-2 ...</td>\n",
       "      <td>20210416 PASC0022</td>\n",
       "      <td>20210416_LC003_001.fcs</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>20210416_LC003_16042021165838.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PASC</td>\n",
       "      <td>long COVID (Post-acute sequelae of SARS-CoV-2 ...</td>\n",
       "      <td>20210427 PASC0021</td>\n",
       "      <td>20210427_LC004_001.fcs</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>20210427_LC004_27042021140712.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PASC</td>\n",
       "      <td>long COVID (Post-acute sequelae of SARS-CoV-2 ...</td>\n",
       "      <td>20210511 PASC0017</td>\n",
       "      <td>20210511_LC005_001.fcs</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>20210511_LC005_11052021145607.pdf, 20210511_LC...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Study                                  Disease/Condition          Subfolder  \\\n",
       "0  PASC  long COVID (Post-acute sequelae of SARS-CoV-2 ...  20210413 PASC0019   \n",
       "1  PASC  long COVID (Post-acute sequelae of SARS-CoV-2 ...  20210416 PASC0020   \n",
       "2  PASC  long COVID (Post-acute sequelae of SARS-CoV-2 ...  20210416 PASC0022   \n",
       "3  PASC  long COVID (Post-acute sequelae of SARS-CoV-2 ...  20210427 PASC0021   \n",
       "4  PASC  long COVID (Post-acute sequelae of SARS-CoV-2 ...  20210511 PASC0017   \n",
       "\n",
       "                        FCS File  Year Month  Is there a PDF report?  \\\n",
       "0  20210413_LC001_BAL_01_001.fcs  2021     4                    True   \n",
       "1         20210416_LC002_001.fcs  2021     4                    True   \n",
       "2         20210416_LC003_001.fcs  2021     4                    True   \n",
       "3         20210427_LC004_001.fcs  2021     4                    True   \n",
       "4         20210511_LC005_001.fcs  2021     5                    True   \n",
       "\n",
       "   # of PDF reports associated with fcs file  \\\n",
       "0                                          1   \n",
       "1                                          1   \n",
       "2                                          1   \n",
       "3                                          1   \n",
       "4                                          2   \n",
       "\n",
       "                                  PDF reports names:  Unnamed: 9 Unnamed: 10  \n",
       "0           20210413_LC001_BAL_01_13042021165347.pdf         NaN         NaN  \n",
       "1                  20210416_LC002_16042021164810.pdf         NaN         NaN  \n",
       "2                  20210416_LC003_16042021165838.pdf         NaN         NaN  \n",
       "3                  20210427_LC004_27042021140712.pdf         NaN         NaN  \n",
       "4  20210511_LC005_11052021145607.pdf, 20210511_LC...         NaN         NaN  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inventory = pd.read_csv(\"ML flow analysis - Copy of Inventory 2025.csv\")\n",
    "inventory.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a18315",
   "metadata": {},
   "source": [
    "Now get rid of the rows where fcs files dont have the pdfs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09113737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study\n",
      "Abbvie              27\n",
      "Duke_ozone          42\n",
      "Lung Transplant    644\n",
      "PASC                30\n",
      "SCRIPT             988\n",
      "WashU_BAL           13\n",
      "dtype: int64\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "inventory_clean = inventory[inventory[\"Is there a PDF report?\"] == True]\n",
    "\n",
    "groups_count = inventory_clean.groupby(\"Study\").size()\n",
    "\n",
    "# print(groups_count)\n",
    "# print(groups_count[\"WashU_BAL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab399f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Study', 'Disease/Condition', 'Subfolder', 'FCS File', 'Year', 'Month',\n",
       "       'Is there a PDF report?', '# of PDF reports associated with fcs file',\n",
       "       'PDF reports names:', 'Unnamed: 9', 'Unnamed: 10'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "studies = inventory_clean['Study'].unique()\n",
    "sampled_dfs = []\n",
    "\n",
    "for study in studies:\n",
    "    if groups_count[study] >= 20:\n",
    "        study_sample = inventory_clean[inventory_clean['Study'] == study].sample(n=20, random_state=42) # Sample 20 rows for each study\n",
    "        sampled_dfs.append(study_sample)\n",
    "        \n",
    "    else:\n",
    "        sampled_dfs.append(inventory_clean[inventory_clean['Study'] == study])\n",
    "        \n",
    "sampled_df = pd.concat(sampled_dfs, ignore_index=True)# Concatenate all samples\n",
    "\n",
    "sampled_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77f3e159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Study</th>\n",
       "      <th>Disease/Condition</th>\n",
       "      <th>Subfolder</th>\n",
       "      <th>FCS File</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Is there a PDF report?</th>\n",
       "      <th># of PDF reports associated with fcs file</th>\n",
       "      <th>PDF reports names:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PASC</td>\n",
       "      <td>long COVID (Post-acute sequelae of SARS-CoV-2 ...</td>\n",
       "      <td>20220719 PASC0175</td>\n",
       "      <td>20220719_PASC0175_001.fcs</td>\n",
       "      <td>2022</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>20220719_PASC0175_19072022165905.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PASC</td>\n",
       "      <td>long COVID (Post-acute sequelae of SARS-CoV-2 ...</td>\n",
       "      <td>20220131 PASC0113</td>\n",
       "      <td>20220131_PASC0113_001.fcs</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>20220131_PASC0113_31012022135046.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PASC</td>\n",
       "      <td>long COVID (Post-acute sequelae of SARS-CoV-2 ...</td>\n",
       "      <td>20220418 PASC0145</td>\n",
       "      <td>20220418_PASC0145_001.fcs</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>20220418_PASC0145_18042022154345.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PASC</td>\n",
       "      <td>long COVID (Post-acute sequelae of SARS-CoV-2 ...</td>\n",
       "      <td>20220209 PASC0122</td>\n",
       "      <td>20220209_PASC0122_001.fcs</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>20220209_PASC0122_09022022164948.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PASC</td>\n",
       "      <td>long COVID (Post-acute sequelae of SARS-CoV-2 ...</td>\n",
       "      <td>20210727 PASC0049</td>\n",
       "      <td>20210727_LC009_BAL01_001.fcs</td>\n",
       "      <td>2021</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>20210727_LC009_BAL01_27072021164852.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Lung Transplant</td>\n",
       "      <td>pulmonary fibrosis</td>\n",
       "      <td>/gpfs/projects/b1042/MisharinLab/anna/all_LT_n...</td>\n",
       "      <td>20210805_LT014_001.fcs</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>20210805_LT014_05082021175022.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Lung Transplant</td>\n",
       "      <td>pulmonary fibrosis</td>\n",
       "      <td>/gpfs/projects/b1042/MisharinLab/anna/all_LT_n...</td>\n",
       "      <td>20230927_LT243 LUL-3_001.fcs</td>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>20230927_LT243 LUL-3_27092023174017.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Lung Transplant</td>\n",
       "      <td>pulmonary fibrosis</td>\n",
       "      <td>/gpfs/projects/b1042/MisharinLab/anna/all_LT_n...</td>\n",
       "      <td>20230310_LT175 RML03_001.fcs</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>20230310_LT175 RML03_10032023174949.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Lung Transplant</td>\n",
       "      <td>pulmonary fibrosis</td>\n",
       "      <td>/gpfs/projects/b1042/MisharinLab/anna/all_LT_n...</td>\n",
       "      <td>20230429_LT195 LUL-01_001.fcs</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>20230429_LT195 LUL-01_29042023103718.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Lung Transplant</td>\n",
       "      <td>pulmonary fibrosis</td>\n",
       "      <td>/gpfs/projects/b1042/MisharinLab/anna/all_LT_n...</td>\n",
       "      <td>20240108_LT337-RML-2_001.fcs</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>20240108_LT337-RML-2_08012025175016.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Study                                  Disease/Condition  \\\n",
       "0               PASC  long COVID (Post-acute sequelae of SARS-CoV-2 ...   \n",
       "1               PASC  long COVID (Post-acute sequelae of SARS-CoV-2 ...   \n",
       "2               PASC  long COVID (Post-acute sequelae of SARS-CoV-2 ...   \n",
       "3               PASC  long COVID (Post-acute sequelae of SARS-CoV-2 ...   \n",
       "4               PASC  long COVID (Post-acute sequelae of SARS-CoV-2 ...   \n",
       "..               ...                                                ...   \n",
       "108  Lung Transplant                                 pulmonary fibrosis   \n",
       "109  Lung Transplant                                 pulmonary fibrosis   \n",
       "110  Lung Transplant                                 pulmonary fibrosis   \n",
       "111  Lung Transplant                                 pulmonary fibrosis   \n",
       "112  Lung Transplant                                 pulmonary fibrosis   \n",
       "\n",
       "                                             Subfolder  \\\n",
       "0                                    20220719 PASC0175   \n",
       "1                                    20220131 PASC0113   \n",
       "2                                    20220418 PASC0145   \n",
       "3                                    20220209 PASC0122   \n",
       "4                                    20210727 PASC0049   \n",
       "..                                                 ...   \n",
       "108  /gpfs/projects/b1042/MisharinLab/anna/all_LT_n...   \n",
       "109  /gpfs/projects/b1042/MisharinLab/anna/all_LT_n...   \n",
       "110  /gpfs/projects/b1042/MisharinLab/anna/all_LT_n...   \n",
       "111  /gpfs/projects/b1042/MisharinLab/anna/all_LT_n...   \n",
       "112  /gpfs/projects/b1042/MisharinLab/anna/all_LT_n...   \n",
       "\n",
       "                          FCS File  Year Month  Is there a PDF report?  \\\n",
       "0        20220719_PASC0175_001.fcs  2022     7                    True   \n",
       "1        20220131_PASC0113_001.fcs  2022     1                    True   \n",
       "2        20220418_PASC0145_001.fcs  2022     4                    True   \n",
       "3        20220209_PASC0122_001.fcs  2022     2                    True   \n",
       "4     20210727_LC009_BAL01_001.fcs  2021     7                    True   \n",
       "..                             ...   ...   ...                     ...   \n",
       "108         20210805_LT014_001.fcs  2021     8                    True   \n",
       "109   20230927_LT243 LUL-3_001.fcs  2023     9                    True   \n",
       "110   20230310_LT175 RML03_001.fcs  2023     3                    True   \n",
       "111  20230429_LT195 LUL-01_001.fcs  2023     4                    True   \n",
       "112   20240108_LT337-RML-2_001.fcs  2024     1                    True   \n",
       "\n",
       "     # of PDF reports associated with fcs file  \\\n",
       "0                                            1   \n",
       "1                                            1   \n",
       "2                                            1   \n",
       "3                                            1   \n",
       "4                                            1   \n",
       "..                                         ...   \n",
       "108                                          1   \n",
       "109                                          1   \n",
       "110                                          1   \n",
       "111                                          1   \n",
       "112                                          1   \n",
       "\n",
       "                           PDF reports names:  \n",
       "0        20220719_PASC0175_19072022165905.pdf  \n",
       "1        20220131_PASC0113_31012022135046.pdf  \n",
       "2        20220418_PASC0145_18042022154345.pdf  \n",
       "3        20220209_PASC0122_09022022164948.pdf  \n",
       "4     20210727_LC009_BAL01_27072021164852.pdf  \n",
       "..                                        ...  \n",
       "108         20210805_LT014_05082021175022.pdf  \n",
       "109   20230927_LT243 LUL-3_27092023174017.pdf  \n",
       "110   20230310_LT175 RML03_10032023174949.pdf  \n",
       "111  20230429_LT195 LUL-01_29042023103718.pdf  \n",
       "112   20240108_LT337-RML-2_08012025175016.pdf  \n",
       "\n",
       "[113 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df.drop(columns = ['Unnamed: 9', 'Unnamed: 10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b89c21f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df.to_csv(os.path.join(\".\",\"training_set_sampled.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d452f3",
   "metadata": {},
   "source": [
    "All the scripts bellow how to tak the original folder, find the files from the training set dataset and save them to one folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9402730d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied: 20220915_LT97 LUL_001.fcs\n",
      "Copied: 20240308_LT260 LUL-1_001.fcs\n",
      "Copied: 20230430_LT192 RML-04_001.fcs\n",
      "Copied: 20221226_LT156 LUL DONOR_001.fcs\n",
      "Copied: 20230927_LT243 LUL-1_001.fcs\n",
      "Copied: 20230219_LT178 LUL-2_001.fcs\n",
      "Copied: 20211111_LT017 RML_001.fcs\n",
      "Copied: 20231029_LT240 LUL-01_001.fcs\n",
      "Copied: 20230729_LT224 LUL-3_001.fcs\n",
      "Copied: 20220901_LT093 LUL_001.fcs\n",
      "Copied: 20240225_LT261-RML-25FEB2024-2_001.fcs\n",
      "Copied: 20241110_LT323-LUL-3_001.fcs\n",
      "Copied: 20230107_LT174 LLL_001.fcs\n",
      "Copied: 2023909_LT232-RML-04_001.fcs\n",
      "Copied: 20241231_LT335 LUL_001.fcs\n",
      "Copied: 20210805_LT014_001.fcs\n",
      "Copied: 20230927_LT243 LUL-3_001.fcs\n",
      "Copied: 20230310_LT175 RML03_001.fcs\n",
      "Copied: 20230429_LT195 LUL-01_001.fcs\n",
      "Copied: 20240108_LT337-RML-2_001.fcs\n",
      "\n",
      "Finished! Copied 20 files to testing_data\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "SOURCE_FOLDER = \"all_LT_new_trial\"  # Where the original files are stored\n",
    "DESTINATION_FOLDER = \"testing_data\"  # Where to copy the files\n",
    "FILE_COLUMN = \"FCS File\"  # Column in your DataFrame that contains filenames\n",
    "\n",
    "# Make sure the destination folder exists\n",
    "os.makedirs(DESTINATION_FOLDER, exist_ok=True)\n",
    "sampled_LTs = sampled_df[sampled_df[\"Study\"] == \"Lung Transplant\"]\n",
    "# Get the list of files from your sampled DataFrame\n",
    "files_to_copy = sampled_LTs[FILE_COLUMN].tolist()\n",
    "\n",
    "# Copy each file\n",
    "for filename in files_to_copy:\n",
    "    source_path = os.path.join(SOURCE_FOLDER, filename)\n",
    "    destination_path = os.path.join(DESTINATION_FOLDER, filename)\n",
    "    \n",
    "    try:\n",
    "        shutil.copy2(source_path, destination_path)\n",
    "        print(f\"Copied: {filename}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error copying {filename}: {str(e)}\")\n",
    "\n",
    "print(f\"\\nFinished! Copied {len(files_to_copy)} files to {DESTINATION_FOLDER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68a4bed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied: 20220915_LT97 LUL_15092022181342.pdf\n",
      "Copied: 20240308_LT260 LUL-1_08032024142010.pdf\n",
      "Copied: 20230430_LT192 RML-04_30042023131201.pdf\n",
      "Copied: 20221226_LT156 LUL DONOR_26122022204201.pdf\n",
      "Copied: 20230927_LT243 LUL-1_27092023173126.pdf\n",
      "Copied: 20230219_LT178 LUL-2_19022023170056.pdf\n",
      "Copied: 20211111_LT017 RML_11112021171101.pdf\n",
      "Copied: 20231029_LT240 LUL-01_29102023191800.pdf\n",
      "Copied: 20230729_LT224 LUL-3_30072023022645.pdf\n",
      "Copied: 20220901_LT093 LUL_01092022160209.pdf\n",
      "Copied: 20240225_LT261-RML-25FEB2024-2_25022024165726.pdf\n",
      "Copied: 20241110_LT323-LUL-3_10112024073924.pdf\n",
      "Copied: 20230107_LT174 LLL_12012023150405.pdf\n",
      "Copied: 2023909_LT232-RML-04_09092023144524.pdf\n",
      "Copied: 20241231_LT335 LUL_31122024182312.pdf\n",
      "Copied: 20210805_LT014_05082021175022.pdf\n",
      "Copied: 20230927_LT243 LUL-3_27092023174017.pdf\n",
      "Copied: 20230310_LT175 RML03_10032023174949.pdf\n",
      "Copied: 20230429_LT195 LUL-01_29042023103718.pdf\n",
      "Copied: 20240108_LT337-RML-2_08012025175016.pdf\n",
      "\n",
      "Finished! Copied 20 files to testing_data\n"
     ]
    }
   ],
   "source": [
    "FILE_COLUMN = \"PDF reports names:\"  # Column in your DataFrame that contains filenames\n",
    "\n",
    "# Make sure the destination folder exists\n",
    "os.makedirs(DESTINATION_FOLDER, exist_ok=True)\n",
    "sampled_LTs = sampled_df[sampled_df[\"Study\"] == \"Lung Transplant\"]\n",
    "# Get the list of files from your sampled DataFrame\n",
    "files_to_copy = sampled_LTs[FILE_COLUMN].tolist()\n",
    "\n",
    "# Copy each file\n",
    "for filename in files_to_copy:\n",
    "    source_path = os.path.join(SOURCE_FOLDER, filename)\n",
    "    destination_path = os.path.join(DESTINATION_FOLDER, filename)\n",
    "    \n",
    "    try:\n",
    "        shutil.copy2(source_path, destination_path)\n",
    "        print(f\"Copied: {filename}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error copying {filename}: {str(e)}\")\n",
    "\n",
    "print(f\"\\nFinished! Copied {len(files_to_copy)} files to {DESTINATION_FOLDER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e0d0400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied: 20241106_2131-BAL-00_001.fcs (from SCRIPT/2024_09_10_11_12)\n",
      "Copied: 20250117_2145-BAL-00_001.fcs (from SCRIPT/2025_01_02_03_04_05)\n",
      "Copied: 20250307_2159-BAL-00_001.fcs (from SCRIPT/2025_01_02_03_04_05)\n",
      "Copied: 20250111_2140-BAL-07_001.fcs (from SCRIPT/2025_01_02_03_04_05)\n",
      "Copied: 20250111_2143-BAL-00_001.fcs (from SCRIPT/2025_01_02_03_04_05)\n",
      "Copied: 20240817_2112-BAL-00_001.fcs (from SCRIPT/2024_06_07_08)\n",
      "Copied: 20200524_1293-BAL-09_003.fcs (from SCRIPT/2020_05)\n",
      "Copied: 20220410_1619-BAL-02_001.fcs (from SCRIPT/2022_04)\n",
      "Copied: 20200929_1386-BAL-00_002.fcs (from SCRIPT/2020_09)\n",
      "Copied: 20210208_1472-BAL-00_001.fcs (from SCRIPT/2021_02)\n",
      "Copied: 20210306_1483-BAL-00_001.fcs (from SCRIPT/2021_03)\n",
      "Copied: 20230519_1714-BAL-00_001.fcs (from SCRIPT/2023_05)\n",
      "Copied: 20221209_1679-BAL-00_001.fcs (from SCRIPT/2022_12)\n",
      "Copied: 20210628_1529-BAL-04_001.fcs (from SCRIPT/2021_06)\n",
      "Copied: 20230823_2022-BAL-07_001.fcs (from SCRIPT/2023_06_07_08)\n",
      "Copied: 20210728_1539-BAL-04_001.fcs (from SCRIPT/2021_07)\n",
      "Copied: 20210903_1561-BAL-00_001.fcs (from SCRIPT/2021_09)\n",
      "Copied: 20200422_1261-BAL-00_002.fcs (from SCRIPT/2020_04)\n",
      "Copied: 20211025_1579-BAL-06_001.fcs (from SCRIPT/2021_10)\n",
      "Copied: 20230203_1690-BAL-00_001.fcs (from SCRIPT/2023_01_02_03)\n",
      "\n",
      "Summary:\n",
      "Successfully copied: 20 files\n",
      "Not found: 0 files\n",
      "Errors: 0 files\n",
      "Destination: testing_data\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Repeat for SCRIPT\"\"\"\n",
    "\n",
    "SOURCE_FOLDER = \"SCRIPT\"  # Where the original files are stored\n",
    "DESTINATION_FOLDER = \"testing_data\"  # Where to copy the files\n",
    "FILE_COLUMN = \"FCS File\"  # Column in your DataFrame that contains filenames\n",
    "\n",
    "# Make sure the destination folder exists\n",
    "os.makedirs(DESTINATION_FOLDER, exist_ok=True)\n",
    "sampled_LTs = sampled_df[sampled_df[\"Study\"] == \"SCRIPT\"]\n",
    "# Get the list of files from your sampled DataFrame\n",
    "files_to_copy = sampled_LTs[FILE_COLUMN].tolist()\n",
    "\n",
    "# Create a dictionary to track found/not found files\n",
    "copy_results = {\n",
    "    'copied': 0,\n",
    "    'not_found': [],\n",
    "    'errors': []\n",
    "}\n",
    "\n",
    "# Walk through all subdirectories to find the files\n",
    "for root, dirs, files in os.walk(SOURCE_FOLDER):\n",
    "    for file in files:\n",
    "        if file in files_to_copy:\n",
    "            source_path = os.path.join(root, file)\n",
    "            destination_path = os.path.join(DESTINATION_FOLDER, file)\n",
    "            \n",
    "            try:\n",
    "                shutil.copy2(source_path, destination_path)\n",
    "                print(f\"Copied: {file} (from {root})\")\n",
    "                copy_results['copied'] += 1\n",
    "                # Remove found file from list to avoid duplicate searches\n",
    "                files_to_copy.remove(file)\n",
    "            except Exception as e:\n",
    "                print(f\"Error copying {file}: {str(e)}\")\n",
    "                copy_results['errors'].append(file)\n",
    "\n",
    "# Check for any files that weren't found\n",
    "for missing_file in files_to_copy:\n",
    "    print(f\"File not found in any subfolder: {missing_file}\")\n",
    "    copy_results['not_found'].append(missing_file)\n",
    "\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"Successfully copied: {copy_results['copied']} files\")\n",
    "print(f\"Not found: {len(copy_results['not_found'])} files\")\n",
    "print(f\"Errors: {len(copy_results['errors'])} files\")\n",
    "print(f\"Destination: {DESTINATION_FOLDER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b87a2e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied: 20241106_2131-BAL-00_06112024145829.pdf (from SCRIPT/2024_09_10_11_12)\n",
      "Copied: 20250111_2140-BAL-07_11012025185416.pdf (from SCRIPT/2025_01_02_03_04_05)\n",
      "Copied: 20250307_2159-BAL-00_07032025153324.pdf (from SCRIPT/2025_01_02_03_04_05)\n",
      "Copied: 20250117_2145-BAL-00_17012025150930.pdf (from SCRIPT/2025_01_02_03_04_05)\n",
      "Copied: 20250111_2143-BAL-00_11012025190140.pdf (from SCRIPT/2025_01_02_03_04_05)\n",
      "Copied: 20240817_2112-BAL-00_17082024184946.pdf (from SCRIPT/2024_06_07_08)\n",
      "Copied: 20200524_1293-BAL-09_24052020174439.pdf (from SCRIPT/2020_05)\n",
      "Copied: 20220410_1619-BAL-02_10042022131259.pdf (from SCRIPT/2022_04)\n",
      "Copied: 20200929_1386-BAL-00_29092020120023.pdf (from SCRIPT/2020_09)\n",
      "Copied: 20210208_1472-BAL-00_09022021162816.pdf (from SCRIPT/2021_02)\n",
      "Copied: 20210306_1483-BAL-00_06032021162128.pdf (from SCRIPT/2021_03)\n",
      "Copied: 20230519_1714-BAL-00_19052023154815.pdf (from SCRIPT/2023_05)\n",
      "Copied: 20221209_1679-BAL-00_09122022164849.pdf (from SCRIPT/2022_12)\n",
      "Copied: 20210628_1529-BAL-04_28062021180947 (1).pdf (from SCRIPT/2021_06)\n",
      "Copied: 20230823_2022-BAL-07_23082023193206.pdf (from SCRIPT/2023_06_07_08)\n",
      "Copied: 20210728_1539-BAL-04_28072021155201.pdf (from SCRIPT/2021_07)\n",
      "Copied: 20210903_1561-BAL-00_03092021171622.pdf (from SCRIPT/2021_09)\n",
      "Copied: 20200422_1261-BAL-00_22042020181302.pdf (from SCRIPT/2020_04)\n",
      "Copied: 20211025_1579-BAL-06_25102021161708.pdf (from SCRIPT/2021_10)\n",
      "Copied: 20230203_1690-BAL-00_03022023173906.pdf (from SCRIPT/2023_01_02_03)\n",
      "\n",
      "Summary:\n",
      "Successfully copied: 20 files\n",
      "Not found: 0 files\n",
      "Errors: 0 files\n",
      "Destination: testing_data\n"
     ]
    }
   ],
   "source": [
    "FILE_COLUMN = \"PDF reports names:\"  # Column in your DataFrame that contains filenames\n",
    "\n",
    "# Make sure the destination folder exists\n",
    "os.makedirs(DESTINATION_FOLDER, exist_ok=True)\n",
    "sampled_LTs = sampled_df[sampled_df[\"Study\"] == \"SCRIPT\"]\n",
    "# Get the list of files from your sampled DataFrame\n",
    "files_to_copy = sampled_LTs[FILE_COLUMN].tolist()\n",
    "\n",
    "# Create a dictionary to track found/not found files\n",
    "copy_results = {\n",
    "    'copied': 0,\n",
    "    'not_found': [],\n",
    "    'errors': []\n",
    "}\n",
    "\n",
    "# Walk through all subdirectories to find the files\n",
    "for root, dirs, files in os.walk(SOURCE_FOLDER):\n",
    "    for file in files:\n",
    "        if file in files_to_copy:\n",
    "            source_path = os.path.join(root, file)\n",
    "            destination_path = os.path.join(DESTINATION_FOLDER, file)\n",
    "            \n",
    "            try:\n",
    "                shutil.copy2(source_path, destination_path)\n",
    "                print(f\"Copied: {file} (from {root})\")\n",
    "                copy_results['copied'] += 1\n",
    "                # Remove found file from list to avoid duplicate searches\n",
    "                files_to_copy.remove(file)\n",
    "            except Exception as e:\n",
    "                print(f\"Error copying {file}: {str(e)}\")\n",
    "                copy_results['errors'].append(file)\n",
    "\n",
    "# Check for any files that weren't found\n",
    "for missing_file in files_to_copy:\n",
    "    print(f\"File not found in any subfolder: {missing_file}\")\n",
    "    copy_results['not_found'].append(missing_file)\n",
    "\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"Successfully copied: {copy_results['copied']} files\")\n",
    "print(f\"Not found: {len(copy_results['not_found'])} files\")\n",
    "print(f\"Errors: {len(copy_results['errors'])} files\")\n",
    "print(f\"Destination: {DESTINATION_FOLDER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8cc84e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied: 20231012_Abb Control-1-BAL-2_001.fcs\n",
      "Copied: 20240417_AbbSSc06_RML_001.fcs\n",
      "Copied: 20240918_AbbSSc03-9Mo-BAL_001.fcs\n",
      "Copied: 20250122_AbbSSc06-9mo_blood_001.fcs\n",
      "Copied: 20240117_Abb04_BAL_RML_001.fcs\n",
      "Copied: 20241120_AbbSSc04-RML-20NOV2024_001.fcs\n",
      "Copied: 20240821_AbbControl-02-RML_001.fcs\n",
      "Copied: 20231006_AbbSsc02-2_001.fcs\n",
      "Copied: 20240731_AbbVie_02_9mo_BAL_001.fcs\n",
      "Copied: 20231012_Abb Control-1-BAL-1_001.fcs\n",
      "File not found: 20240117_Abb04_Whole_Blood_001_001.fcs\n",
      "File not found: 20231006_AbbSsc02 flow_001.fcs\n",
      "Copied: 20231006_AbbSsc02-1_001.fcs\n",
      "File not found: 20230926_AbbSsc003_RML_001.fcs\n",
      "Copied: 20250311_AbbSSc_09_BAL_001.fcs\n",
      "Copied: 20231006_AbbSsc02-1_001.fcs\n",
      "File not found: 20230926_AbbSsc003_WholeBlood_001.fcs\n",
      "Copied: 20231012_Abb Control-1-BAL-2_001.fcs\n",
      "Copied: 20241106_AbbSSc-RML-05_001.fcs\n",
      "Copied: 20250319_AbbSSc_11_BAL_001.fcs\n",
      "\n",
      "Finished! Copied 20 files to testing_data\n"
     ]
    }
   ],
   "source": [
    "SOURCE_FOLDER = \"Abbvie\"  # Where the original files are stored\n",
    "DESTINATION_FOLDER = \"testing_data\"  # Where to copy the files\n",
    "FILE_COLUMN = \"FCS File\"  # Column in your DataFrame that contains filenames\n",
    "\n",
    "# Make sure the destination folder exists\n",
    "os.makedirs(DESTINATION_FOLDER, exist_ok=True)\n",
    "sampled_LTs = sampled_df[sampled_df[\"Study\"] == \"Abbvie\"]\n",
    "# Get the list of files from your sampled DataFrame\n",
    "files_to_copy = sampled_LTs[FILE_COLUMN].tolist()\n",
    "\n",
    "# Copy each file\n",
    "for filename in files_to_copy:\n",
    "    source_path = os.path.join(SOURCE_FOLDER, filename)\n",
    "    destination_path = os.path.join(DESTINATION_FOLDER, filename)\n",
    "    \n",
    "    try:\n",
    "        shutil.copy2(source_path, destination_path)\n",
    "        print(f\"Copied: {filename}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error copying {filename}: {str(e)}\")\n",
    "\n",
    "print(f\"\\nFinished! Copied {len(files_to_copy)} files to {DESTINATION_FOLDER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50fb63d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied: 20231012_Abb Control-1-BAL-2_13102023150141.pdf\n",
      "Copied: 20240417_AbbSSc06_RML_17042024190721.pdf\n",
      "Copied: 20240918_AbbSSc03-9Mo-BAL_18092024182229.pdf\n",
      "Copied: 20250122_AbbSSc06-9mo_22012025184258.pdf\n",
      "File not found: 20240117_Abb04_BAL_RML_17012024161829.pdf, 20240117_Abb04_Whole_Blood_001_17012024162431.pdf\n",
      "Copied: 20241120_AbbSSc04-RML-20NOV2024_20112024172351.pdf\n",
      "Copied: 20240821_AbbControl-02-RML_21082024173646.pdf\n",
      "Copied: 20231006_AbbSsc02-2_06102023145840.pdf\n",
      "Copied: 20240731_AbbVie_02_9mo_BAL_31072024153506.pdf\n",
      "Copied: 20231012_Abb Control-1-BAL-1_13102023144758.pdf\n",
      "File not found: 20240117_Abb04_BAL_RML_17012024161829.pdf, 20240117_Abb04_Whole_Blood_001_17012024162431.pdf\n",
      "File not found: 20231006_AbbSsc02 flow_06102023150128.pdf\n",
      "Copied: 20231006_AbbSsc02-1_06102023144916.pdf\n",
      "File not found: 20230926_AbbSsc003_RML_26092023185702.pdf, 20230926_AbbSsc003_WholeBlood_26092023175830.pdf\n",
      "Copied: 20250311_AbbSSc_09_BAL_11032025174753.pdf\n",
      "Copied: 20231006_AbbSsc02-1_06102023144916.pdf\n",
      "File not found: 20230926_AbbSsc003_RML_26092023185702.pdf, 20230926_AbbSsc003_WholeBlood_26092023175830.pdf\n",
      "Copied: 20231012_Abb Control-1-BAL-2_13102023150141.pdf\n",
      "Copied: 20241106_AbbSSc-RML-05_06112024173119.pdf\n",
      "Copied: 20250319_AbbSSc_11_BAL_19032025173004.pdf\n",
      "\n",
      "Finished! Copied 20 files to testing_data\n"
     ]
    }
   ],
   "source": [
    "SOURCE_FOLDER = \"Abbvie\"  # Where the original files are stored\n",
    "DESTINATION_FOLDER = \"testing_data\"  # Where to copy the files\n",
    "FILE_COLUMN = \"PDF reports names:\"  # Column in your DataFrame that contains filenames\n",
    "\n",
    "# Make sure the destination folder exists\n",
    "os.makedirs(DESTINATION_FOLDER, exist_ok=True)\n",
    "sampled_LTs = sampled_df[sampled_df[\"Study\"] == \"Abbvie\"]\n",
    "# Get the list of files from your sampled DataFrame\n",
    "files_to_copy = sampled_LTs[FILE_COLUMN].tolist()\n",
    "\n",
    "# Copy each file\n",
    "for filename in files_to_copy:\n",
    "    source_path = os.path.join(SOURCE_FOLDER, filename)\n",
    "    destination_path = os.path.join(DESTINATION_FOLDER, filename)\n",
    "    \n",
    "    try:\n",
    "        shutil.copy2(source_path, destination_path)\n",
    "        print(f\"Copied: {filename}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error copying {filename}: {str(e)}\")\n",
    "\n",
    "print(f\"\\nFinished! Copied {len(files_to_copy)} files to {DESTINATION_FOLDER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c31fbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied: 20240117_Abb04_BAL_RML_001.fcs (from Abbvie_local/20230117 AbbSSc04)\n",
      "Copied: 20240117_Abb04_Whole_Blood_001_001.fcs (from Abbvie_local/20230117 AbbSSc04)\n",
      "Copied: 20230926_AbbSsc003_WholeBlood_001.fcs (from Abbvie_local/20230926 AbbSSc003)\n",
      "Copied: 20230926_AbbSsc003_RML_001.fcs (from Abbvie_local/20230926 AbbSSc003)\n",
      "Copied: 20231006_AbbSsc02 flow_001.fcs (from Abbvie_local/20231006 AbbSSc02)\n",
      "Copied: 20231006_AbbSsc02-2_001.fcs (from Abbvie_local/20231006 AbbSSc02)\n",
      "Copied: 20231006_AbbSsc02-1_001.fcs (from Abbvie_local/20231006 AbbSSc02)\n",
      "Copied: 20231012_Abb Control-1-BAL-1_001.fcs (from Abbvie_local/20231013 abb-control-1 and 2)\n",
      "Copied: 20231012_Abb Control-1-BAL-2_001.fcs (from Abbvie_local/20231013 abb-control-1 and 2)\n",
      "File not found in any subfolder: 20240417_AbbSSc06_RML_001.fcs\n",
      "File not found in any subfolder: 20240918_AbbSSc03-9Mo-BAL_001.fcs\n",
      "File not found in any subfolder: 20250122_AbbSSc06-9mo_blood_001.fcs\n",
      "File not found in any subfolder: 20241120_AbbSSc04-RML-20NOV2024_001.fcs\n",
      "File not found in any subfolder: 20240821_AbbControl-02-RML_001.fcs\n",
      "File not found in any subfolder: 20240731_AbbVie_02_9mo_BAL_001.fcs\n",
      "File not found in any subfolder: 20250311_AbbSSc_09_BAL_001.fcs\n",
      "File not found in any subfolder: 20231006_AbbSsc02-1_001.fcs\n",
      "File not found in any subfolder: 20231012_Abb Control-1-BAL-2_001.fcs\n",
      "File not found in any subfolder: 20241106_AbbSSc-RML-05_001.fcs\n",
      "File not found in any subfolder: 20250319_AbbSSc_11_BAL_001.fcs\n",
      "\n",
      "Summary:\n",
      "Successfully copied: 9 files\n",
      "Not found: 11 files\n",
      "Errors: 0 files\n",
      "Destination: testing_data\n"
     ]
    }
   ],
   "source": [
    "SOURCE_FOLDER = \"Abbvie_local\"  # Where the original files are stored\n",
    "DESTINATION_FOLDER = \"testing_data\"  # Where to copy the files\n",
    "FILE_COLUMN = \"FCS File\"  # Column in your DataFrame that contains filenames\n",
    "\n",
    "# Make sure the destination folder exists\n",
    "os.makedirs(DESTINATION_FOLDER, exist_ok=True)\n",
    "sampled_LTs = sampled_df[sampled_df[\"Study\"] == \"Abbvie\"]\n",
    "# Get the list of files from your sampled DataFrame\n",
    "files_to_copy = sampled_LTs[FILE_COLUMN].tolist()\n",
    "\n",
    "# Create a dictionary to track found/not found files\n",
    "copy_results = {\n",
    "    'copied': 0,\n",
    "    'not_found': [],\n",
    "    'errors': []\n",
    "}\n",
    "\n",
    "# Walk through all subdirectories to find the files\n",
    "for root, dirs, files in os.walk(SOURCE_FOLDER):\n",
    "    for file in files:\n",
    "        if file in files_to_copy:\n",
    "            source_path = os.path.join(root, file)\n",
    "            destination_path = os.path.join(DESTINATION_FOLDER, file)\n",
    "            \n",
    "            try:\n",
    "                shutil.copy2(source_path, destination_path)\n",
    "                print(f\"Copied: {file} (from {root})\")\n",
    "                copy_results['copied'] += 1\n",
    "                # Remove found file from list to avoid duplicate searches\n",
    "                files_to_copy.remove(file)\n",
    "            except Exception as e:\n",
    "                print(f\"Error copying {file}: {str(e)}\")\n",
    "                copy_results['errors'].append(file)\n",
    "\n",
    "# Check for any files that weren't found\n",
    "for missing_file in files_to_copy:\n",
    "    print(f\"File not found in any subfolder: {missing_file}\")\n",
    "    copy_results['not_found'].append(missing_file)\n",
    "\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"Successfully copied: {copy_results['copied']} files\")\n",
    "print(f\"Not found: {len(copy_results['not_found'])} files\")\n",
    "print(f\"Errors: {len(copy_results['errors'])} files\")\n",
    "print(f\"Destination: {DESTINATION_FOLDER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a59705c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied: 20231006_AbbSsc02-2_06102023145840.pdf (from Abbvie_local/20231006 AbbSSc02)\n",
      "Copied: 20231006_AbbSsc02-1_06102023144916.pdf (from Abbvie_local/20231006 AbbSSc02)\n",
      "Copied: 20231006_AbbSsc02 flow_06102023150128.pdf (from Abbvie_local/20231006 AbbSSc02)\n",
      "Copied: 20231012_Abb Control-1-BAL-2_13102023150141.pdf (from Abbvie_local/20231013 abb-control-1 and 2)\n",
      "Copied: 20231012_Abb Control-1-BAL-1_13102023144758.pdf (from Abbvie_local/20231013 abb-control-1 and 2)\n",
      "File not found in any subfolder: 20240417_AbbSSc06_RML_17042024190721.pdf\n",
      "File not found in any subfolder: 20240918_AbbSSc03-9Mo-BAL_18092024182229.pdf\n",
      "File not found in any subfolder: 20250122_AbbSSc06-9mo_22012025184258.pdf\n",
      "File not found in any subfolder: 20240117_Abb04_BAL_RML_17012024161829.pdf, 20240117_Abb04_Whole_Blood_001_17012024162431.pdf\n",
      "File not found in any subfolder: 20241120_AbbSSc04-RML-20NOV2024_20112024172351.pdf\n",
      "File not found in any subfolder: 20240821_AbbControl-02-RML_21082024173646.pdf\n",
      "File not found in any subfolder: 20240731_AbbVie_02_9mo_BAL_31072024153506.pdf\n",
      "File not found in any subfolder: 20240117_Abb04_BAL_RML_17012024161829.pdf, 20240117_Abb04_Whole_Blood_001_17012024162431.pdf\n",
      "File not found in any subfolder: 20230926_AbbSsc003_RML_26092023185702.pdf, 20230926_AbbSsc003_WholeBlood_26092023175830.pdf\n",
      "File not found in any subfolder: 20250311_AbbSSc_09_BAL_11032025174753.pdf\n",
      "File not found in any subfolder: 20231006_AbbSsc02-1_06102023144916.pdf\n",
      "File not found in any subfolder: 20230926_AbbSsc003_RML_26092023185702.pdf, 20230926_AbbSsc003_WholeBlood_26092023175830.pdf\n",
      "File not found in any subfolder: 20231012_Abb Control-1-BAL-2_13102023150141.pdf\n",
      "File not found in any subfolder: 20241106_AbbSSc-RML-05_06112024173119.pdf\n",
      "File not found in any subfolder: 20250319_AbbSSc_11_BAL_19032025173004.pdf\n",
      "\n",
      "Summary:\n",
      "Successfully copied: 5 files\n",
      "Not found: 15 files\n",
      "Errors: 0 files\n",
      "Destination: testing_data\n"
     ]
    }
   ],
   "source": [
    "SOURCE_FOLDER = \"Abbvie_local\"  # Where the original files are stored\n",
    "DESTINATION_FOLDER = \"testing_data\"  # Where to copy the files\n",
    "FILE_COLUMN = \"PDF reports names:\"  # Column in your DataFrame that contains filenames\n",
    "\n",
    "# Make sure the destination folder exists\n",
    "os.makedirs(DESTINATION_FOLDER, exist_ok=True)\n",
    "sampled_LTs = sampled_df[sampled_df[\"Study\"] == \"Abbvie\"]\n",
    "# Get the list of files from your sampled DataFrame\n",
    "files_to_copy = sampled_LTs[FILE_COLUMN].tolist()\n",
    "\n",
    "# Create a dictionary to track found/not found files\n",
    "copy_results = {\n",
    "    'copied': 0,\n",
    "    'not_found': [],\n",
    "    'errors': []\n",
    "}\n",
    "\n",
    "# Walk through all subdirectories to find the files\n",
    "for root, dirs, files in os.walk(SOURCE_FOLDER):\n",
    "    for file in files:\n",
    "        if file in files_to_copy:\n",
    "            source_path = os.path.join(root, file)\n",
    "            destination_path = os.path.join(DESTINATION_FOLDER, file)\n",
    "            \n",
    "            try:\n",
    "                shutil.copy2(source_path, destination_path)\n",
    "                print(f\"Copied: {file} (from {root})\")\n",
    "                copy_results['copied'] += 1\n",
    "                # Remove found file from list to avoid duplicate searches\n",
    "                files_to_copy.remove(file)\n",
    "            except Exception as e:\n",
    "                print(f\"Error copying {file}: {str(e)}\")\n",
    "                copy_results['errors'].append(file)\n",
    "\n",
    "# Check for any files that weren't found\n",
    "for missing_file in files_to_copy:\n",
    "    print(f\"File not found in any subfolder: {missing_file}\")\n",
    "    copy_results['not_found'].append(missing_file)\n",
    "\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"Successfully copied: {copy_results['copied']} files\")\n",
    "print(f\"Not found: {len(copy_results['not_found'])} files\")\n",
    "print(f\"Errors: {len(copy_results['errors'])} files\")\n",
    "print(f\"Destination: {DESTINATION_FOLDER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29daa68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied: 20220525_MOZEPH035-2_001.fcs (from Duke_ozone/20220525 MOZEPH035-2)\n",
      "Copied: 20240229_MOLI005-BAL-01_001.fcs (from Duke_ozone/20240229 MOLI005-BAL-01)\n",
      "Copied: 20211028_CXCL10_CXCR3_010-1_001.fcs (from Duke_ozone/20211028 CXCL10_CXCR3_010-1)\n",
      "Copied: 20230831_MOLI_001_BAL_01_001.fcs (from Duke_ozone/20230831 MOLI001_BAL_1)\n",
      "Copied: 20240222_MOLI006-BAL-01_001.fcs (from Duke_ozone/20240222 MOLI006-BAL-01)\n",
      "Copied: 20220324_MOZEPH030-2_001.fcs (from Duke_ozone/20220324 MOZEPH030-2)\n",
      "Copied: 20220519_MOZEPH034-1_001.fcs (from Duke_ozone/20220618 MOZEPH034-1)\n",
      "Copied: 20220603_MOZEPH033-1_001.fcs (from Duke_ozone/20220603 MOZEPH033-1)\n",
      "Copied: 20211104_MOZEPH015-2_001.fcs (from Duke_ozone/20211104 MOZEPH015-2)\n",
      "Copied: 20230727_MOZEPH039-02_siglec8TEST_001.fcs (from Duke_ozone/20230727 MOZEPH039-2)\n",
      "Copied: 20230727_MOZEPH039-02_001.fcs (from Duke_ozone/20230727 MOZEPH039-2)\n",
      "Copied: 202101202_MOZEPH020-2_001.fcs (from Duke_ozone/20211202 MOZEPH020-2 DUKE)\n",
      "Copied: 20220701_MOZEPH033-2_001.fcs (from Duke_ozone/20220701 MOZEPH033-2)\n",
      "Copied: 20240606_MOLI007-BAL-02_001.fcs (from Duke_ozone/20240606 MOLI007-BAL-2)\n",
      "Copied: 20230629_MOZEPH039 BAL-1_001.fcs (from Duke_ozone/20230629 MOZEPH039-1)\n",
      "Copied: 20220331_MOZEPH026-2_001.fcs (from Duke_ozone/20220331 MOZEPH026-2)\n",
      "Copied: 20230818_CXCR3-012-01_001.fcs (from Duke_ozone/20230818 CXCR3-012-1)\n",
      "Copied: 20220113_MOZEPH026_1_001.fcs (from Duke_ozone/20220113 MOZEPH026-1)\n",
      "Copied: 20220120_CXCR3-011_001.fcs (from Duke_ozone/20220120 CXCR3_011-1)\n",
      "Copied: 2023914_CXCR3012-02 BAL_001.fcs (from Duke_ozone/2023914_CXCR3012-02 BAL)\n",
      "\n",
      "Summary:\n",
      "Successfully copied: 20 files\n",
      "Not found: 0 files\n",
      "Errors: 0 files\n",
      "Destination: testing_data\n"
     ]
    }
   ],
   "source": [
    "SOURCE_FOLDER = \"Duke_ozone\"  # Where the original files are stored\n",
    "DESTINATION_FOLDER = \"testing_data\"  # Where to copy the files\n",
    "FILE_COLUMN = \"FCS File\"  # Column in your DataFrame that contains filenames\n",
    "\n",
    "# Make sure the destination folder exists\n",
    "os.makedirs(DESTINATION_FOLDER, exist_ok=True)\n",
    "sampled_LTs = sampled_df[sampled_df[\"Study\"] == \"Duke_ozone\"]\n",
    "# Get the list of files from your sampled DataFrame\n",
    "files_to_copy = sampled_LTs[FILE_COLUMN].tolist()\n",
    "\n",
    "# Create a dictionary to track found/not found files\n",
    "copy_results = {\n",
    "    'copied': 0,\n",
    "    'not_found': [],\n",
    "    'errors': []\n",
    "}\n",
    "\n",
    "# Walk through all subdirectories to find the files\n",
    "for root, dirs, files in os.walk(SOURCE_FOLDER):\n",
    "    for file in files:\n",
    "        if file in files_to_copy:\n",
    "            source_path = os.path.join(root, file)\n",
    "            destination_path = os.path.join(DESTINATION_FOLDER, file)\n",
    "            \n",
    "            try:\n",
    "                shutil.copy2(source_path, destination_path)\n",
    "                print(f\"Copied: {file} (from {root})\")\n",
    "                copy_results['copied'] += 1\n",
    "                # Remove found file from list to avoid duplicate searches\n",
    "                files_to_copy.remove(file)\n",
    "            except Exception as e:\n",
    "                print(f\"Error copying {file}: {str(e)}\")\n",
    "                copy_results['errors'].append(file)\n",
    "\n",
    "# Check for any files that weren't found\n",
    "for missing_file in files_to_copy:\n",
    "    print(f\"File not found in any subfolder: {missing_file}\")\n",
    "    copy_results['not_found'].append(missing_file)\n",
    "\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"Successfully copied: {copy_results['copied']} files\")\n",
    "print(f\"Not found: {len(copy_results['not_found'])} files\")\n",
    "print(f\"Errors: {len(copy_results['errors'])} files\")\n",
    "print(f\"Destination: {DESTINATION_FOLDER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2028be03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied: 20220525_MOZEPH035-2_26052022151945.pdf (from Duke_ozone/20220525 MOZEPH035-2)\n",
      "Copied: 20240229_MOLI005-BAL-01_29022024174300.pdf (from Duke_ozone/20240229 MOLI005-BAL-01)\n",
      "Copied: 20211028_CXCL10_CXCR3_010-1_28102021123049.pdf (from Duke_ozone/20211028 CXCL10_CXCR3_010-1)\n",
      "Copied: 20230831_MOLI_001_BAL_01_31082023161746.pdf (from Duke_ozone/20230831 MOLI001_BAL_1)\n",
      "Copied: 20240222_MOLI006-BAL-01_22022024171339.pdf (from Duke_ozone/20240222 MOLI006-BAL-01)\n",
      "Copied: 20220324_MOZEPH030-2_24032022173448.pdf (from Duke_ozone/20220324 MOZEPH030-2)\n",
      "Copied: 20220519_MOZEPH034-1_22062022173858.pdf (from Duke_ozone/20220618 MOZEPH034-1)\n",
      "Copied: 20220603_MOZEPH033-1_03062022162219.pdf (from Duke_ozone/20220603 MOZEPH033-1)\n",
      "Copied: 202101202_MOZEPH020-2_02122021155727.pdf (from Duke_ozone/20211202 MOZEPH020-2 DUKE)\n",
      "Copied: 20220701_MOZEPH033-2_01072022173031.pdf (from Duke_ozone/20220701 MOZEPH033-2)\n",
      "Copied: 20240606_MOLI007-BAL-02_06062024145002.pdf (from Duke_ozone/20240606 MOLI007-BAL-2)\n",
      "Copied: 20230629_MOZEPH039 BAL-1_29062023162001.pdf (from Duke_ozone/20230629 MOZEPH039-1)\n",
      "Copied: 20220331_MOZEPH026-2_31032022155427.pdf (from Duke_ozone/20220331 MOZEPH026-2)\n",
      "Copied: 20230818_CXCR3-012-01_18082023172825.pdf (from Duke_ozone/20230818 CXCR3-012-1)\n",
      "Copied: 20220113_MOZEPH026_1_13012022130332.pdf (from Duke_ozone/20220113 MOZEPH026-1)\n",
      "Copied: 20220120_CXCR3-011_20012022172831.pdf (from Duke_ozone/20220120 CXCR3_011-1)\n",
      "Copied: 2023914_CXCR3012-02 BAL_14092023173726.pdf (from Duke_ozone/2023914_CXCR3012-02 BAL)\n",
      "File not found in any subfolder: 20230727_MOZEPH039-02_27072023194203.pdf, 20230727_MOZEPH039-02_siglec8TEST_27072023194926.pdf\n",
      "File not found in any subfolder: 20211104_MOZEPH015-2_04112021161658-FSMC02D511VML85.pdf, 20211104_MOZEPH015-2_04112021161658.pdf\n",
      "File not found in any subfolder: 20230727_MOZEPH039-02_27072023194203.pdf, 20230727_MOZEPH039-02_siglec8TEST_27072023194926.pdf\n",
      "\n",
      "Summary:\n",
      "Successfully copied: 17 files\n",
      "Not found: 3 files\n",
      "Errors: 0 files\n",
      "Destination: testing_data\n"
     ]
    }
   ],
   "source": [
    "SOURCE_FOLDER = \"Duke_ozone\"  # Where the original files are stored\n",
    "DESTINATION_FOLDER = \"testing_data\"  # Where to copy the files\n",
    "FILE_COLUMN = \"PDF reports names:\"  # Column in your DataFrame that contains filenames\n",
    "\n",
    "# Make sure the destination folder exists\n",
    "os.makedirs(DESTINATION_FOLDER, exist_ok=True)\n",
    "sampled_LTs = sampled_df[sampled_df[\"Study\"] == \"Duke_ozone\"]\n",
    "# Get the list of files from your sampled DataFrame\n",
    "files_to_copy = sampled_LTs[FILE_COLUMN].tolist()\n",
    "\n",
    "# Create a dictionary to track found/not found files\n",
    "copy_results = {\n",
    "    'copied': 0,\n",
    "    'not_found': [],\n",
    "    'errors': []\n",
    "}\n",
    "\n",
    "# Walk through all subdirectories to find the files\n",
    "for root, dirs, files in os.walk(SOURCE_FOLDER):\n",
    "    for file in files:\n",
    "        if file in files_to_copy:\n",
    "            source_path = os.path.join(root, file)\n",
    "            destination_path = os.path.join(DESTINATION_FOLDER, file)\n",
    "            \n",
    "            try:\n",
    "                shutil.copy2(source_path, destination_path)\n",
    "                print(f\"Copied: {file} (from {root})\")\n",
    "                copy_results['copied'] += 1\n",
    "                # Remove found file from list to avoid duplicate searches\n",
    "                files_to_copy.remove(file)\n",
    "            except Exception as e:\n",
    "                print(f\"Error copying {file}: {str(e)}\")\n",
    "                copy_results['errors'].append(file)\n",
    "\n",
    "# Check for any files that weren't found\n",
    "for missing_file in files_to_copy:\n",
    "    print(f\"File not found in any subfolder: {missing_file}\")\n",
    "    copy_results['not_found'].append(missing_file)\n",
    "\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"Successfully copied: {copy_results['copied']} files\")\n",
    "print(f\"Not found: {len(copy_results['not_found'])} files\")\n",
    "print(f\"Errors: {len(copy_results['errors'])} files\")\n",
    "print(f\"Destination: {DESTINATION_FOLDER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4ca908a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied: 20240415_WU009-BAL-000_16042024162153.pdf (from WashU_BAL/WU009)\n",
      "Copied: 20240514_WU014-BAL-000_14052024170113.pdf (from WashU_BAL/WU014)\n",
      "Copied: 20240408_WU012-BAL-000_08052024181906.pdf (from WashU_BAL/WU012)\n",
      "Copied: 20240120_WU006-BAL-000_20012024182416.pdf (from WashU_BAL/WU006)\n",
      "Copied: 20240417_WU010-BAL-000_17042024190814.pdf (from WashU_BAL/WU010)\n",
      "Copied: 20240113_WU003-BAL-001_13012024182143.pdf (from WashU_BAL/WU003)\n",
      "Copied: 20240120_WU005-BAL-001_20012024180904.pdf (from WashU_BAL/WU005)\n",
      "Copied: 20240111_WU002-BAL-000_11012024134612.pdf (from WashU_BAL/WU002)\n",
      "Copied: 20240511_WU013-BAL-000_11052024203423.pdf (from WashU_BAL/WU013)\n",
      "Copied: 20240404_WU011-BAL-000_03052024180310.pdf (from WashU_BAL/WU011)\n",
      "Copied: 20240410_WU008-BAL-000_10042024172723.pdf (from WashU_BAL/WU008)\n",
      "Copied: 20240104_WU001-BAL-000_04012024173621.pdf (from WashU_BAL/WU001)\n",
      "Copied: 20240117_WU004-BAL-000_17012024155605 2.pdf (from WashU_BAL/WU004)\n",
      "\n",
      "Summary:\n",
      "Successfully copied: 13 files\n",
      "Not found: 0 files\n",
      "Errors: 0 files\n",
      "Destination: testing_data\n"
     ]
    }
   ],
   "source": [
    "SOURCE_FOLDER = \"WashU_BAL\"  # Where the original files are stored\n",
    "DESTINATION_FOLDER = \"testing_data\"  # Where to copy the files\n",
    "FILE_COLUMN = \"PDF reports names:\"  # Column in your DataFrame that contains filenames\n",
    "\n",
    "# Make sure the destination folder exists\n",
    "os.makedirs(DESTINATION_FOLDER, exist_ok=True)\n",
    "sampled_LTs = sampled_df[sampled_df[\"Study\"] == \"WashU_BAL\"]\n",
    "# Get the list of files from your sampled DataFrame\n",
    "files_to_copy = sampled_LTs[FILE_COLUMN].tolist()\n",
    "\n",
    "# Create a dictionary to track found/not found files\n",
    "copy_results = {\n",
    "    'copied': 0,\n",
    "    'not_found': [],\n",
    "    'errors': []\n",
    "}\n",
    "\n",
    "# Walk through all subdirectories to find the files\n",
    "for root, dirs, files in os.walk(SOURCE_FOLDER):\n",
    "    for file in files:\n",
    "        if file in files_to_copy:\n",
    "            source_path = os.path.join(root, file)\n",
    "            destination_path = os.path.join(DESTINATION_FOLDER, file)\n",
    "            \n",
    "            try:\n",
    "                shutil.copy2(source_path, destination_path)\n",
    "                print(f\"Copied: {file} (from {root})\")\n",
    "                copy_results['copied'] += 1\n",
    "                # Remove found file from list to avoid duplicate searches\n",
    "                files_to_copy.remove(file)\n",
    "            except Exception as e:\n",
    "                print(f\"Error copying {file}: {str(e)}\")\n",
    "                copy_results['errors'].append(file)\n",
    "\n",
    "# Check for any files that weren't found\n",
    "for missing_file in files_to_copy:\n",
    "    print(f\"File not found in any subfolder: {missing_file}\")\n",
    "    copy_results['not_found'].append(missing_file)\n",
    "\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"Successfully copied: {copy_results['copied']} files\")\n",
    "print(f\"Not found: {len(copy_results['not_found'])} files\")\n",
    "print(f\"Errors: {len(copy_results['errors'])} files\")\n",
    "print(f\"Destination: {DESTINATION_FOLDER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e0e3836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied: 20240415_WU009-BAL-000_001.fcs (from WashU_BAL/WU009)\n",
      "Copied: 20240514_WU014-BAL-000_001.fcs (from WashU_BAL/WU014)\n",
      "Copied: 20240408_WU012-BAL-000_001.fcs (from WashU_BAL/WU012)\n",
      "Copied: 20240120_WU006-BAL-000_001.fcs (from WashU_BAL/WU006)\n",
      "Copied: 20240417_WU010-BAL-000_001.fcs (from WashU_BAL/WU010)\n",
      "Copied: 20240113_WU003-BAL-001_001.fcs (from WashU_BAL/WU003)\n",
      "Copied: 20240120_WU005-BAL-001_001.fcs (from WashU_BAL/WU005)\n",
      "Copied: 20240111_WU002-BAL-000_001.fcs (from WashU_BAL/WU002)\n",
      "Copied: 20240511_WU013-BAL-000_001.fcs (from WashU_BAL/WU013)\n",
      "Copied: 20240404_WU011-BAL-000_001.fcs (from WashU_BAL/WU011)\n",
      "Copied: 20240410_WU008-BAL-000_001.fcs (from WashU_BAL/WU008)\n",
      "Copied: 20240104_WU001-BAL-000_001.fcs (from WashU_BAL/WU001)\n",
      "Copied: 20240117_WU004-BAL-000_001 2.fcs (from WashU_BAL/WU004)\n",
      "\n",
      "Summary:\n",
      "Successfully copied: 13 files\n",
      "Not found: 0 files\n",
      "Errors: 0 files\n",
      "Destination: testing_data\n"
     ]
    }
   ],
   "source": [
    "SOURCE_FOLDER = \"WashU_BAL\"  # Where the original files are stored\n",
    "DESTINATION_FOLDER = \"testing_data\"  # Where to copy the files\n",
    "FILE_COLUMN = \"FCS File\"  # Column in your DataFrame that contains filenames\n",
    "\n",
    "# Make sure the destination folder exists\n",
    "os.makedirs(DESTINATION_FOLDER, exist_ok=True)\n",
    "sampled_LTs = sampled_df[sampled_df[\"Study\"] == \"WashU_BAL\"]\n",
    "# Get the list of files from your sampled DataFrame\n",
    "files_to_copy = sampled_LTs[FILE_COLUMN].tolist()\n",
    "\n",
    "# Create a dictionary to track found/not found files\n",
    "copy_results = {\n",
    "    'copied': 0,\n",
    "    'not_found': [],\n",
    "    'errors': []\n",
    "}\n",
    "\n",
    "# Walk through all subdirectories to find the files\n",
    "for root, dirs, files in os.walk(SOURCE_FOLDER):\n",
    "    for file in files:\n",
    "        if file in files_to_copy:\n",
    "            source_path = os.path.join(root, file)\n",
    "            destination_path = os.path.join(DESTINATION_FOLDER, file)\n",
    "            \n",
    "            try:\n",
    "                shutil.copy2(source_path, destination_path)\n",
    "                print(f\"Copied: {file} (from {root})\")\n",
    "                copy_results['copied'] += 1\n",
    "                # Remove found file from list to avoid duplicate searches\n",
    "                files_to_copy.remove(file)\n",
    "            except Exception as e:\n",
    "                print(f\"Error copying {file}: {str(e)}\")\n",
    "                copy_results['errors'].append(file)\n",
    "\n",
    "# Check for any files that weren't found\n",
    "for missing_file in files_to_copy:\n",
    "    print(f\"File not found in any subfolder: {missing_file}\")\n",
    "    copy_results['not_found'].append(missing_file)\n",
    "\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"Successfully copied: {copy_results['copied']} files\")\n",
    "print(f\"Not found: {len(copy_results['not_found'])} files\")\n",
    "print(f\"Errors: {len(copy_results['errors'])} files\")\n",
    "print(f\"Destination: {DESTINATION_FOLDER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cee9d43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied: 20210416_LC002_16042021164810.pdf (from PASC/20210416 PASC0020)\n",
      "Copied: 20220209_PASC0122_09022022164948.pdf (from PASC/20220209 PASC0122)\n",
      "Copied: 20210416_LC003_16042021165838.pdf (from PASC/20210416 PASC0022)\n",
      "Copied: 20220427_PASC0147_28042022152330.pdf (from PASC/20220427 PASC0147)\n",
      "Copied: 20220127_PASC0115_27012022164834.pdf (from PASC/20220131 PASC0115)\n",
      "Copied: 20220323_PASC0137_23032022102957.pdf (from PASC/20220322 PASC0137)\n",
      "Copied: 20210727_LC009_BAL01_27072021164852.pdf (from PASC/20210727 PASC0049)\n",
      "Copied: 20210805_LT039_05082021173239.pdf (from PASC/20210805 PASC0059)\n",
      "Copied: 20210511_LC006_11052021145530.pdf (from PASC/20210511 PASC0018)\n",
      "Copied: 202101220_PASC0107_20122021180655.pdf (from PASC/20211220 PASC0107)\n",
      "Copied: 20210427_LC004_27042021140712.pdf (from PASC/20210427 PASC0021)\n",
      "Copied: 20220105_PASC0111_05012022144531.pdf (from PASC/20220105 PASC0111)\n",
      "Copied: 20210413_LC001_BAL_01_13042021165347.pdf (from PASC/20210413 PASC0019)\n",
      "Copied: 20221004_PASC0192_04102022165004.pdf (from PASC/20221004 PASC0192)\n",
      "Copied: 20220719_PASC0175_19072022165905.pdf (from PASC/20220719 PASC0175)\n",
      "Copied: 202101215_PASC0105_15122021165809.pdf (from PASC/20211215 PASC0105)\n",
      "Copied: 20220418_PASC0145_18042022154345.pdf (from PASC/20220418 PASC0145)\n",
      "Copied: 20220524_PASC0156_24052022161515.pdf (from PASC/20220524 PASC0156)\n",
      "Copied: 20220131_PASC0113_31012022135046.pdf (from PASC/20220131 PASC0113)\n",
      "File not found in any subfolder: 20210511_LC005_11052021145607.pdf, 20210511_LC005_11052021150712.pdf\n",
      "\n",
      "Summary:\n",
      "Successfully copied: 19 files\n",
      "Not found: 1 files\n",
      "Errors: 0 files\n",
      "Destination: testing_data\n"
     ]
    }
   ],
   "source": [
    "SOURCE_FOLDER = \"PASC\"  # Where the original files are stored\n",
    "DESTINATION_FOLDER = \"testing_data\"  # Where to copy the files\n",
    "FILE_COLUMN = \"PDF reports names:\"  # Column in your DataFrame that contains filenames\n",
    "\n",
    "# Make sure the destination folder exists\n",
    "os.makedirs(DESTINATION_FOLDER, exist_ok=True)\n",
    "sampled_LTs = sampled_df[sampled_df[\"Study\"] == \"PASC\"]\n",
    "# Get the list of files from your sampled DataFrame\n",
    "files_to_copy = sampled_LTs[FILE_COLUMN].tolist()\n",
    "\n",
    "# Create a dictionary to track found/not found files\n",
    "copy_results = {\n",
    "    'copied': 0,\n",
    "    'not_found': [],\n",
    "    'errors': []\n",
    "}\n",
    "\n",
    "# Walk through all subdirectories to find the files\n",
    "for root, dirs, files in os.walk(SOURCE_FOLDER):\n",
    "    for file in files:\n",
    "        if file in files_to_copy:\n",
    "            source_path = os.path.join(root, file)\n",
    "            destination_path = os.path.join(DESTINATION_FOLDER, file)\n",
    "            \n",
    "            try:\n",
    "                shutil.copy2(source_path, destination_path)\n",
    "                print(f\"Copied: {file} (from {root})\")\n",
    "                copy_results['copied'] += 1\n",
    "                # Remove found file from list to avoid duplicate searches\n",
    "                files_to_copy.remove(file)\n",
    "            except Exception as e:\n",
    "                print(f\"Error copying {file}: {str(e)}\")\n",
    "                copy_results['errors'].append(file)\n",
    "\n",
    "# Check for any files that weren't found\n",
    "for missing_file in files_to_copy:\n",
    "    print(f\"File not found in any subfolder: {missing_file}\")\n",
    "    copy_results['not_found'].append(missing_file)\n",
    "\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"Successfully copied: {copy_results['copied']} files\")\n",
    "print(f\"Not found: {len(copy_results['not_found'])} files\")\n",
    "print(f\"Errors: {len(copy_results['errors'])} files\")\n",
    "print(f\"Destination: {DESTINATION_FOLDER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e62d677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied: 20210416_LC002_001.fcs (from PASC/20210416 PASC0020)\n",
      "Copied: 20220209_PASC0122_001.fcs (from PASC/20220209 PASC0122)\n",
      "Copied: 20210416_LC003_001.fcs (from PASC/20210416 PASC0022)\n",
      "Copied: 20220427_PASC0147_001.fcs (from PASC/20220427 PASC0147)\n",
      "Copied: 20220127_PASC0115_001.fcs (from PASC/20220131 PASC0115)\n",
      "Copied: 20220323_PASC0137_001.fcs (from PASC/20220322 PASC0137)\n",
      "Copied: 20210727_LC009_BAL01_001.fcs (from PASC/20210727 PASC0049)\n",
      "Copied: 20210805_LT039_001.fcs (from PASC/20210805 PASC0059)\n",
      "Copied: 20210511_LC006_001.fcs (from PASC/20210511 PASC0018)\n",
      "Copied: 202101220_PASC0107_001.fcs (from PASC/20211220 PASC0107)\n",
      "Copied: 20210427_LC004_001.fcs (from PASC/20210427 PASC0021)\n",
      "Copied: 20220105_PASC0111_001.fcs (from PASC/20220105 PASC0111)\n",
      "Copied: 20210511_LC005_001.fcs (from PASC/20210511 PASC0017)\n",
      "Copied: 20210413_LC001_BAL_01_001.fcs (from PASC/20210413 PASC0019)\n",
      "Copied: 20221004_PASC0192_001.fcs (from PASC/20221004 PASC0192)\n",
      "Copied: 20220719_PASC0175_001.fcs (from PASC/20220719 PASC0175)\n",
      "Copied: 202101215_PASC0105_001.fcs (from PASC/20211215 PASC0105)\n",
      "Copied: 20220418_PASC0145_001.fcs (from PASC/20220418 PASC0145)\n",
      "Copied: 20220524_PASC0156_001.fcs (from PASC/20220524 PASC0156)\n",
      "Copied: 20220131_PASC0113_001.fcs (from PASC/20220131 PASC0113)\n",
      "\n",
      "Summary:\n",
      "Successfully copied: 20 files\n",
      "Not found: 0 files\n",
      "Errors: 0 files\n",
      "Destination: testing_data\n"
     ]
    }
   ],
   "source": [
    "SOURCE_FOLDER = \"PASC\"  # Where the original files are stored\n",
    "DESTINATION_FOLDER = \"testing_data\"  # Where to copy the files\n",
    "FILE_COLUMN = \"FCS File\"  # Column in your DataFrame that contains filenames\n",
    "\n",
    "# Make sure the destination folder exists\n",
    "os.makedirs(DESTINATION_FOLDER, exist_ok=True)\n",
    "sampled_LTs = sampled_df[sampled_df[\"Study\"] == \"PASC\"]\n",
    "# Get the list of files from your sampled DataFrame\n",
    "files_to_copy = sampled_LTs[FILE_COLUMN].tolist()\n",
    "\n",
    "# Create a dictionary to track found/not found files\n",
    "copy_results = {\n",
    "    'copied': 0,\n",
    "    'not_found': [],\n",
    "    'errors': []\n",
    "}\n",
    "\n",
    "# Walk through all subdirectories to find the files\n",
    "for root, dirs, files in os.walk(SOURCE_FOLDER):\n",
    "    for file in files:\n",
    "        if file in files_to_copy:\n",
    "            source_path = os.path.join(root, file)\n",
    "            destination_path = os.path.join(DESTINATION_FOLDER, file)\n",
    "            \n",
    "            try:\n",
    "                shutil.copy2(source_path, destination_path)\n",
    "                print(f\"Copied: {file} (from {root})\")\n",
    "                copy_results['copied'] += 1\n",
    "                # Remove found file from list to avoid duplicate searches\n",
    "                files_to_copy.remove(file)\n",
    "            except Exception as e:\n",
    "                print(f\"Error copying {file}: {str(e)}\")\n",
    "                copy_results['errors'].append(file)\n",
    "\n",
    "# Check for any files that weren't found\n",
    "for missing_file in files_to_copy:\n",
    "    print(f\"File not found in any subfolder: {missing_file}\")\n",
    "    copy_results['not_found'].append(missing_file)\n",
    "\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"Successfully copied: {copy_results['copied']} files\")\n",
    "print(f\"Not found: {len(copy_results['not_found'])} files\")\n",
    "print(f\"Errors: {len(copy_results['errors'])} files\")\n",
    "print(f\"Destination: {DESTINATION_FOLDER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07d54e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (UNITO_demo)",
   "language": "python",
   "name": "unito_demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
